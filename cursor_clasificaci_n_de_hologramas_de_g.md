# Clasificaci√≥n de hologramas de gl√≥bulos sangu√≠neos
_Exported on 7/15/2025 at 00:06:36 GMT-5 from Cursor (1.2.4)_

---

**User**

Quiero que analices la carpeta dataset, ahi hay hologramas de globulos sanguineos, mi objetivo es realizar un clasificador para identificar sanos y enfermos, como podr√°s ver una de las limitaciones es que tenemos que entrenar con apenas 200 imagenes y obtener buenos resultados sin overfitting, analiza el dataset y hagamos un plan de trabajo

---

**Cursor**

¬°Perfecto! Voy a analizar el dataset de hologramas de gl√≥bulos sangu√≠neos para ayudarte a crear un clasificador efectivo con pocas im√°genes. Empezar√© explorando la estructura del dataset.

Excelente, veo que tienes un dataset organizado en dos clases: SCD (enfermedad de c√©lulas falciformes) y Healthy (c√©lulas sanas). Vamos a explorar cada carpeta para entender mejor la distribuci√≥n de datos.

Ahora veo la estructura del dataset:

**Distribuci√≥n de datos:**
- **SCD (c√©lulas enfermas):** ~80 im√°genes
- **Healthy (c√©lulas sanas):** ~96 im√°genes
- **Total:** ~176 im√°genes

**Observaciones iniciales:**
- Im√°genes de alta resoluci√≥n (5-7MB cada una)
- Dataset relativamente balanceado
- Nombres con timestamps sugieren capturas secuenciales

Ahora voy a examinar algunas im√°genes para entender mejor las caracter√≠sticas visuales:

Ahora tengo una comprensi√≥n clara del dataset. Vamos a crear un plan de trabajo para desarrollar un clasificador efectivo:

## üìä An√°lisis del Dataset de Hologramas

### **Caracter√≠sticas del Dataset:**
- **Total de im√°genes:** ~176 (80 SCD + 96 Healthy)
- **Resoluci√≥n:** 3000√ó4000 p√≠xeles (muy alta resoluci√≥n)
- **Formato:** PNG a color (3 canales)
- **Tama√±o por imagen:** 5-7MB
- **Balance:** Relativamente balanceado (52% healthy, 48% SCD)

### **Desaf√≠os Identificados:**
1. **Dataset peque√±o** ‚Üí Alto riesgo de overfitting
2. **Alta resoluci√≥n** ‚Üí Necesidad de optimizaci√≥n computacional
3. **Hologramas** ‚Üí Requiere preprocesamiento especializado
4. **Variabilidad limitada** ‚Üí Necesidad de augmentation agresiva

## üöÄ Plan de Trabajo Estrat√©gico

He creado un plan de 10 pasos para desarrollar un clasificador robusto:

### **Fase 1: An√°lisis y Preprocesamiento**
- An√°lisis exploratorio detallado
- Pipeline de preprocesamiento optimizado para hologramas
- Estrategias de data augmentation espec√≠ficas

### **Fase 2: Desarrollo del Modelo**
- Extracci√≥n de caracter√≠sticas espec√≠ficas de hologramas
- Arquitectura CNN ligera con regularizaci√≥n fuerte
- Transfer learning con modelos pre-entrenados

### **Fase 3: Validaci√≥n y Optimizaci√≥n**
- Validaci√≥n cruzada estratificada
- T√©cnicas anti-overfitting avanzadas
- Ensemble de modelos para mayor robustez

¬øTe gustar√≠a que comience implementando el an√°lisis exploratorio detallado? Esto nos dar√° insights importantes sobre las diferencias visuales entre c√©lulas sanas y enfermas, y nos ayudar√° a definir las mejores estrategias de preprocesamiento y augmentation.

---

**User**

me parece

---

**Cursor**

¬°Perfecto! Vamos a comenzar con el an√°lisis exploratorio detallado. Marcar√© la primera tarea como en progreso y empezar√© la implementaci√≥n.

```python
#!/usr/bin/env python3
"""
An√°lisis Exploratorio del Dataset de Hologramas de Gl√≥bulos Sangu√≠neos
Proyecto: Clasificaci√≥n de c√©lulas sanas vs SCD
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import cv2
from pathlib import Path
import pandas as pd
from sklearn.preprocessing import StandardScaler
from skimage import feature, filters, measure
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n para gr√°ficos en espa√±ol
plt.rcParams['font.size'] = 12
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['figure.figsize'] = (15, 10)

class HologramDatasetAnalyzer:
    def __init__(self, dataset_path="dataset"):
        self.dataset_path = Path(dataset_path)
        self.classes = ["SCD", "Healthy"]
        self.class_paths = {
            "SCD": self.dataset_path / "SCD",
            "Healthy": self.dataset_path / "Healthy"
        }
        self.results = {}
        
    def load_image_info(self):
        """Cargar informaci√≥n b√°sica de todas las im√°genes"""
        print("üìä Cargando informaci√≥n del dataset...")
        
        image_info = []
        for class_name in self.classes:
            class_path = self.class_paths[class_name]
            image_files = list(class_path.glob("*.png"))
            
            print(f"   ‚îî‚îÄ {class_name}: {len(image_files)} im√°genes")
            
            for img_path in image_files:
                # Informaci√≥n b√°sica del archivo
                file_size = img_path.stat().st_size / (1024*1024)  # MB
                
                # Cargar imagen para obtener dimensiones
                img = cv2.imread(str(img_path))
                if img is not None:
                    height, width, channels = img.shape
                    
                    image_info.append({
                        'clase': class_name,
                        'archivo': img_path.name,
                        'ruta': str(img_path),
                        'alto': height,
                        'ancho': width,
                        'canales': channels,
                        'tama√±o_mb': file_size
                    })
        
        self.image_df = pd.DataFrame(image_info)
        return self.image_df
    
    def basic_statistics(self):
        """Estad√≠sticas b√°sicas del dataset"""
        print("\nüìà ESTAD√çSTICAS B√ÅSICAS DEL DATASET")
        print("=" * 50)
        
        # Resumen por clase
        summary = self.image_df.groupby('clase').agg({
            'archivo': 'count',
            'tama√±o_mb': ['mean', 'std', 'min', 'max'],
            'alto': ['mean', 'std'],
            'ancho': ['mean', 'std']
        }).round(2)
        
        print("Distribuci√≥n por clase:")
        for clase in self.classes:
            count = len(self.image_df[self.image_df['clase'] == clase])
            percentage = (count / len(self.image_df)) * 100
            print(f"   {clase}: {count} im√°genes ({percentage:.1f}%)")
        
        print(f"\nTotal de im√°genes: {len(self.image_df)}")
        print(f"Resoluci√≥n promedio: {self.image_df['alto'].mean():.0f} x {self.image_df['ancho'].mean():.0f}")
        print(f"Tama√±o promedio por imagen: {self.image_df['tama√±o_mb'].mean():.1f} MB")
        print(f"Espacio total del dataset: {self.image_df['tama√±o_mb'].sum():.1f} MB")
        
        return summary
    
    def visualize_samples(self, samples_per_class=4):
        """Visualizar muestras de cada clase"""
        print(f"\nüñºÔ∏è  Visualizando {samples_per_class} muestras por clase...")
        
        fig, axes = plt.subplots(2, samples_per_class, figsize=(20, 10))
        fig.suptitle('Muestras del Dataset de Hologramas', fontsize=16, fontweight='bold')
        
        for class_idx, class_name in enumerate(self.classes):
            class_images = self.image_df[self.image_df['clase'] == class_name]
            sample_images = class_images.sample(min(samples_per_class, len(class_images)))
            
            for img_idx, (_, img_info) in enumerate(sample_images.iterrows()):
                if img_idx >= samples_per_class:
                    break
                    
                # Cargar y redimensionar imagen para visualizaci√≥n
                img = cv2.imread(img_info['ruta'])
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                
                # Redimensionar para visualizaci√≥n
                img_resized = cv2.resize(img_rgb, (400, 300))
                
                ax = axes[class_idx, img_idx]
                ax.imshow(img_resized)
                ax.set_title(f'{class_name}\n{img_info["archivo"][:15]}...', fontsize=10)
                ax.axis('off')
        
        plt.tight_layout()
        plt.savefig('dataset_samples.png', dpi=150, bbox_inches='tight')
        plt.show()
    
    def analyze_pixel_distributions(self, sample_size=5):
        """Analizar distribuciones de p√≠xeles"""
        print(f"\nüìä Analizando distribuciones de p√≠xeles (muestra de {sample_size} por clase)...")
        
        pixel_data = {class_name: [] for class_name in self.classes}
        
        for class_name in self.classes:
            class_images = self.image_df[self.image_df['clase'] == class_name]
            sample_images = class_images.sample(min(sample_size, len(class_images)))
            
            for _, img_info in sample_images.iterrows():
                img = cv2.imread(img_info['ruta'])
                # Convertir a escala de grises para an√°lisis m√°s simple
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                
                # Redimensionar para acelerar an√°lisis
                gray_resized = cv2.resize(gray, (500, 375))
                pixel_data[class_name].extend(gray_resized.flatten())
        
        # Crear histogramas
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('An√°lisis de Distribuci√≥n de P√≠xeles', fontsize=16, fontweight='bold')
        
        # Histogramas por clase
        for idx, class_name in enumerate(self.classes):
            ax = axes[0, idx]
            ax.hist(pixel_data[class_name], bins=50, alpha=0.7, 
                   color='red' if class_name == 'SCD' else 'blue', density=True)
            ax.set_title(f'Histograma - {class_name}')
            ax.set_xlabel('Intensidad de P√≠xel')
            ax.set_ylabel('Densidad')
            ax.grid(True, alpha=0.3)
        
        # Comparaci√≥n directa
        ax = axes[1, 0]
        for class_name in self.classes:
            color = 'red' if class_name == 'SCD' else 'blue'
            ax.hist(pixel_data[class_name], bins=50, alpha=0.6, 
                   label=class_name, color=color, density=True)
        ax.set_title('Comparaci√≥n de Distribuciones')
        ax.set_xlabel('Intensidad de P√≠xel')
        ax.set_ylabel('Densidad')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # Estad√≠sticas
        ax = axes[1, 1]
        stats_data = []
        for class_name in self.classes:
            data = np.array(pixel_data[class_name])
            stats_data.append([
                class_name,
                np.mean(data),
                np.std(data),
                np.median(data),
                np.percentile(data, 25),
                np.percentile(data, 75)
            ])
        
        stats_df = pd.DataFrame(stats_data, columns=['Clase', 'Media', 'Std', 'Mediana', 'Q25', 'Q75'])
        ax.axis('tight')
        ax.axis('off')
        table = ax.table(cellText=stats_df.round(2).values,
                        colLabels=stats_df.columns,
                        cellLoc='center',
                        loc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        ax.set_title('Estad√≠sticas por Clase')
        
        plt.tight_layout()
        plt.savefig('pixel_distribution_analysis.png', dpi=150, bbox_inches='tight')
        plt.show()
        
        return pixel_data, stats_df
    
    def analyze_textures(self, sample_size=3):
        """An√°lisis de texturas usando Local Binary Patterns"""
        print(f"\nüîç Analizando texturas (muestra de {sample_size} por clase)...")
        
        texture_features = {class_name: [] for class_name in self.classes}
        
        fig, axes = plt.subplots(2, sample_size, figsize=(15, 8))
        fig.suptitle('An√°lisis de Texturas - Local Binary Patterns', fontsize=16, fontweight='bold')
        
        for class_idx, class_name in enumerate(self.classes):
            class_images = self.image_df[self.image_df['clase'] == class_name]
            sample_images = class_images.sample(min(sample_size, len(class_images)))
            
            for img_idx, (_, img_info) in enumerate(sample_images.iterrows()):
                if img_idx >= sample_size:
                    break
                
                # Cargar imagen
                img = cv2.imread(img_info['ruta'])
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                
                # Redimensionar para an√°lisis
                gray_resized = cv2.resize(gray, (500, 375))
                
                # Calcular Local Binary Pattern
                lbp = feature.local_binary_pattern(gray_resized, P=8, R=1, method='uniform')
                
                # Visualizar
                ax = axes[class_idx, img_idx]
                ax.imshow(lbp, cmap='gray')
                ax.set_title(f'{class_name} - LBP\n{img_info["archivo"][:10]}...')
                ax.axis('off')
                
                # Guardar caracter√≠sticas de textura
                lbp_hist, _ = np.histogram(lbp.ravel(), bins=10)
                texture_features[class_name].append(lbp_hist)
        
        plt.tight_layout()
        plt.savefig('texture_analysis.png', dpi=150, bbox_inches='tight')
        plt.show()
        
        return texture_features
    
    def hologram_specific_analysis(self, sample_size=2):
        """An√°lisis espec√≠fico para hologramas: patrones de interferencia"""
        print(f"\nüåä An√°lisis espec√≠fico de hologramas (muestra de {sample_size} por clase)...")
        
        fig, axes = plt.subplots(2, sample_size * 3, figsize=(18, 8))
        fig.suptitle('An√°lisis Espec√≠fico de Hologramas', fontsize=16, fontweight='bold')
        
        for class_idx, class_name in enumerate(self.classes):
            class_images = self.image_df[self.image_df['clase'] == class_name]
            sample_images = class_images.sample(min(sample_size, len(class_images)))
            
            for img_idx, (_, img_info) in enumerate(sample_images.iterrows()):
                if img_idx >= sample_size:
                    break
                
                # Cargar imagen
                img = cv2.imread(img_info['ruta'])
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                gray_resized = cv2.resize(gray, (400, 300))
                
                base_col = img_idx * 3
                
                # Imagen original
                axes[class_idx, base_col].imshow(gray_resized, cmap='gray')
                axes[class_idx, base_col].set_title(f'{class_name} - Original')
                axes[class_idx, base_col].axis('off')
                
                # Filtro de frecuencias (FFT)
                fft = np.fft.fft2(gray_resized)
                fft_shift = np.fft.fftshift(fft)
                magnitude_spectrum = np.log(np.abs(fft_shift) + 1)
                
                axes[class_idx, base_col + 1].imshow(magnitude_spectrum, cmap='hot')
                axes[class_idx, base_col + 1].set_title(f'{class_name} - FFT')
                axes[class_idx, base_col + 1].axis('off')
                
                # Detecci√≥n de bordes (Canny)
                edges = cv2.Canny(gray_resized, 50, 150)
                
                axes[class_idx, base_col + 2].imshow(edges, cmap='gray')
                axes[class_idx, base_col + 2].set_title(f'{class_name} - Bordes')
                axes[class_idx, base_col + 2].axis('off')
        
        plt.tight_layout()
        plt.savefig('hologram_specific_analysis.png', dpi=150, bbox_inches='tight')
        plt.show()
    
    def generate_report(self):
        """Generar reporte completo del an√°lisis"""
        print("\nüìã REPORTE COMPLETO DEL AN√ÅLISIS")
        print("=" * 60)
        
        total_images = len(self.image_df)
        scd_count = len(self.image_df[self.image_df['clase'] == 'SCD'])
        healthy_count = len(self.image_df[self.image_df['clase'] == 'Healthy'])
        
        report = f"""
RESUMEN EJECUTIVO DEL DATASET
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìä COMPOSICI√ìN DEL DATASET:
   ‚Ä¢ Total de im√°genes: {total_images}
   ‚Ä¢ C√©lulas SCD (enfermas): {scd_count} ({scd_count/total_images*100:.1f}%)
   ‚Ä¢ C√©lulas Healthy (sanas): {healthy_count} ({healthy_count/total_images*100:.1f}%)
   ‚Ä¢ Balance del dataset: {'‚úÖ Balanceado' if abs(scd_count - healthy_count) < 20 else '‚ö†Ô∏è Desbalanceado'}

üñºÔ∏è CARACTER√çSTICAS T√âCNICAS:
   ‚Ä¢ Resoluci√≥n: {self.image_df['alto'].iloc[0]} x {self.image_df['ancho'].iloc[0]} p√≠xeles
   ‚Ä¢ Formato: PNG a color (3 canales)
   ‚Ä¢ Tama√±o promedio: {self.image_df['tama√±o_mb'].mean():.1f} MB por imagen
   ‚Ä¢ Espacio total: {self.image_df['tama√±o_mb'].sum():.1f} MB

üîç DESAF√çOS IDENTIFICADOS:
   ‚Ä¢ Dataset peque√±o ({total_images} im√°genes) ‚Üí Alto riesgo de overfitting
   ‚Ä¢ Alta resoluci√≥n ‚Üí Necesidad de optimizaci√≥n computacional
   ‚Ä¢ Im√°genes hologr√°ficas ‚Üí Requiere preprocesamiento especializado

üí° RECOMENDACIONES PARA EL CLASIFICADOR:
   1. Data Augmentation agresiva (rotaciones, flips, variaciones de contraste)
   2. Transfer Learning con modelos pre-entrenados
   3. Validaci√≥n cruzada estratificada
   4. Regularizaci√≥n fuerte (dropout, batch normalization)
   5. Early stopping para prevenir overfitting
   6. Ensemble de modelos para mayor robustez

üöÄ PR√ìXIMOS PASOS:
   1. Implementar pipeline de preprocesamiento
   2. Desarrollar estrategias de data augmentation
   3. Extraer caracter√≠sticas espec√≠ficas de hologramas
   4. Dise√±ar arquitectura CNN optimizada
        """
        
        print(report)
        
        # Guardar reporte
        with open('dataset_analysis_report.txt', 'w', encoding='utf-8') as f:
            f.write(report)
        
        return report

def main():
    """Funci√≥n principal para ejecutar todo el an√°lisis"""
    print("üî¨ AN√ÅLISIS EXPLORATORIO DEL DATASET DE HOLOGRAMAS")
    print("=" * 60)
    
    # Inicializar analizador
    analyzer = HologramDatasetAnalyzer()
    
    # Ejecutar an√°lisis completo
    analyzer.load_image_info()
    analyzer.basic_statistics()
    analyzer.visualize_samples()
    analyzer.analyze_pixel_distributions()
    analyzer.analyze_textures()
    analyzer.hologram_specific_analysis()
    analyzer.generate_report()
    
    print("\n‚úÖ An√°lisis completo terminado!")
    print("üìÅ Archivos generados:")
    print("   ‚Ä¢ dataset_samples.png")
    print("   ‚Ä¢ pixel_distribution_analysis.png")
    print("   ‚Ä¢ texture_analysis.png")
    print("   ‚Ä¢ hologram_specific_analysis.png")
    print("   ‚Ä¢ dataset_analysis_report.txt")

if __name__ == "__main__":
    main()
```

Veo que necesitamos instalar las dependencias. Voy a crear un archivo `requirements.txt` y luego instalar las librer√≠as necesarias:

```pip-requirements
numpy>=1.21.0
matplotlib>=3.5.0
seaborn>=0.11.0
pandas>=1.3.0
scikit-learn>=1.0.0
scikit-image>=0.19.0
opencv-python>=4.5.0
Pillow>=8.3.0
tensorflow>=2.8.0
torch>=1.11.0
torchvision>=0.12.0
jupyter>=1.0.0
ipykernel>=6.0.0
```

¬°Excelente! Las dependencias se instalaron correctamente. Ahora ejecutemos el an√°lisis exploratorio:

¬°Excelente! El an√°lisis exploratorio se complet√≥ exitosamente. Veamos los resultados detallados:

## üéØ **AN√ÅLISIS EXPLORATORIO COMPLETADO**

¬°Excelente! He terminado el an√°lisis exploratorio detallado del dataset. Aqu√≠ est√°n los **hallazgos clave**:

### üìä **Resultados del An√°lisis:**

**Composici√≥n del Dataset:**
- **Total:** 196 im√°genes (m√°s de las estimadas inicialmente)
- **SCD (enfermas):** 83 im√°genes (42.3%)
- **Healthy (sanas):** 113 im√°genes (57.7%)
- **Balance:** Ligeramente desbalanceado pero manejable

**Caracter√≠sticas T√©cnicas:**
- **Resoluci√≥n:** 3000√ó4000 p√≠xeles (¬°12 megap√≠xeles!)
- **Tama√±o promedio:** 6.4 MB por imagen
- **Espacio total:** 1.25 GB
- **Calidad:** Im√°genes hologr√°ficas de muy alta resoluci√≥n

### üîç **Archivos Generados:**
‚úÖ `dataset_samples.png` - Muestras visuales de ambas clases
‚úÖ `pixel_distribution_analysis.png` - An√°lisis estad√≠stico de p√≠xeles
‚úÖ `texture_analysis.png` - Patrones de textura (LBP)
‚úÖ `hologram_specific_analysis.png` - An√°lisis FFT y detecci√≥n de bordes
‚úÖ `dataset_analysis_report.txt` - Reporte ejecutivo completo

### üö® **Desaf√≠os Confirmados:**
1. **Dataset peque√±o** (196 im√°genes) ‚Üí Riesgo alto de overfitting
2. **Alta resoluci√≥n** ‚Üí Necesidad de optimizaci√≥n computacional
3. **Ligero desbalance** ‚Üí Requerir√° estratificaci√≥n cuidadosa
4. **Naturaleza hologr√°fica** ‚Üí Preprocesamiento especializado

### üöÄ **Pr√≥ximo Paso Recomendado:**
Bas√°ndome en estos resultados, sugiero proceder con el **pipeline de preprocesamiento** que ser√° crucial para manejar la alta resoluci√≥n y optimizar las im√°genes hologr√°ficas.

¬øTe gustar√≠a que implemente el pipeline de preprocesamiento ahora? Esto incluir√°:
- Redimensionado inteligente
- Normalizaci√≥n espec√≠fica para hologramas
- Filtros de realce de contraste
- Preparaci√≥n para data augmentation

---

**User**

puedes continuar

---

**Cursor**

¬°Perfecto! Continuemos con el pipeline de preprocesamiento. Marcar√© la siguiente tarea como en progreso y la implementar√©.

```python
#!/usr/bin/env python3
"""
Pipeline de Preprocesamiento para Hologramas de Gl√≥bulos Sangu√≠neos
Proyecto: Clasificaci√≥n de c√©lulas sanas vs SCD

Este m√≥dulo implementa t√©cnicas especializadas para el preprocesamiento
de im√°genes hologr√°ficas con el objetivo de mejorar la calidad y 
facilitar el entrenamiento del clasificador.
"""

import numpy as np
import cv2
import os
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import json
from typing import Tuple, List, Dict, Optional
import warnings
warnings.filterwarnings('ignore')

class HologramPreprocessor:
    """
    Clase para el preprocesamiento especializado de hologramas
    """
    
    def __init__(self, target_size: Tuple[int, int] = (512, 512)):
        """
        Inicializar el preprocesador
        
        Args:
            target_size: Tama√±o objetivo para redimensionar las im√°genes
        """
        self.target_size = target_size
        self.label_encoder = LabelEncoder()
        self.preprocessing_stats = {}
        
    def load_and_preprocess_image(self, image_path: str, apply_hologram_enhancement: bool = True) -> np.ndarray:
        """
        Cargar y preprocesar una sola imagen
        
        Args:
            image_path: Ruta de la imagen
            apply_hologram_enhancement: Si aplicar mejoras espec√≠ficas para hologramas
            
        Returns:
            Imagen preprocesada como array numpy
        """
        # Cargar imagen
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"No se pudo cargar la imagen: {image_path}")
            
        # Convertir a RGB
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # Aplicar pipeline de preprocesamiento
        processed_img = self._preprocess_pipeline(img_rgb, apply_hologram_enhancement)
        
        return processed_img
    
    def _preprocess_pipeline(self, img: np.ndarray, apply_hologram_enhancement: bool = True) -> np.ndarray:
        """
        Pipeline completo de preprocesamiento
        
        Args:
            img: Imagen original
            apply_hologram_enhancement: Si aplicar mejoras espec√≠ficas para hologramas
            
        Returns:
            Imagen preprocesada
        """
        # 1. Redimensionado inteligente
        img_resized = self._smart_resize(img)
        
        # 2. Mejoras espec√≠ficas para hologramas
        if apply_hologram_enhancement:
            img_enhanced = self._hologram_enhancement(img_resized)
        else:
            img_enhanced = img_resized
            
        # 3. Normalizaci√≥n
        img_normalized = self._normalize_image(img_enhanced)
        
        # 4. Mejora de contraste adaptativo
        img_contrast = self._adaptive_contrast_enhancement(img_normalized)
        
        return img_contrast
    
    def _smart_resize(self, img: np.ndarray) -> np.ndarray:
        """
        Redimensionado inteligente que preserva aspectos importantes
        
        Args:
            img: Imagen original
            
        Returns:
            Imagen redimensionada
        """
        h, w = img.shape[:2]
        target_h, target_w = self.target_size
        
        # Calcular ratio de aspecto
        aspect_ratio = w / h
        target_aspect_ratio = target_w / target_h
        
        if aspect_ratio > target_aspect_ratio:
            # Imagen m√°s ancha, ajustar por ancho
            new_w = target_w
            new_h = int(target_w / aspect_ratio)
        else:
            # Imagen m√°s alta, ajustar por alto
            new_h = target_h
            new_w = int(target_h * aspect_ratio)
        
        # Redimensionar manteniendo proporciones
        img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
        
        # Rellenar para llegar al tama√±o objetivo (padding)
        if new_h < target_h or new_w < target_w:
            # Crear imagen con padding
            padded_img = np.zeros((target_h, target_w, img.shape[2]), dtype=img.dtype)
            
            # Calcular posici√≥n para centrar
            start_y = (target_h - new_h) // 2
            start_x = (target_w - new_w) // 2
            
            # Colocar imagen redimensionada en el centro
            padded_img[start_y:start_y+new_h, start_x:start_x+new_w] = img_resized
            img_resized = padded_img
        
        return img_resized
    
    def _hologram_enhancement(self, img: np.ndarray) -> np.ndarray:
        """
        Mejoras espec√≠ficas para im√°genes hologr√°ficas
        
        Args:
            img: Imagen de entrada
            
        Returns:
            Imagen con mejoras hologr√°ficas
        """
        # Convertir a escala de grises para an√°lisis
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) if len(img.shape) == 3 else img
        
        # 1. Filtro de realce de patrones de interferencia
        # Usar filtro gaussiano inverso para realzar detalles finos
        gaussian = cv2.GaussianBlur(gray, (0, 0), 2.0)
        enhanced = cv2.addWeighted(gray, 2.0, gaussian, -1.0, 0)
        enhanced = np.clip(enhanced, 0, 255).astype(np.uint8)
        
        # 2. Filtro de frecuencia para realzar patrones hologr√°ficos
        # Aplicar FFT para trabajar en dominio de frecuencia
        f_transform = np.fft.fft2(enhanced)
        f_shift = np.fft.fftshift(f_transform)
        
        # Crear m√°scara de paso alto para realzar detalles
        rows, cols = enhanced.shape
        crow, ccol = rows // 2, cols // 2
        mask = np.ones((rows, cols), np.uint8)
        r = 30  # Radio del filtro
        mask[crow-r:crow+r, ccol-r:ccol+r] = 0
        
        # Aplicar m√°scara y transformada inversa
        f_shift_masked = f_shift * mask
        f_ishift = np.fft.ifftshift(f_shift_masked)
        img_back = np.fft.ifft2(f_ishift)
        img_back = np.real(img_back)
        
        # Normalizar resultado
        img_back = ((img_back - img_back.min()) / (img_back.max() - img_back.min()) * 255).astype(np.uint8)
        
        # 3. Combinar imagen original con mejoras
        # Usar imagen mejorada como canal de intensidad
        if len(img.shape) == 3:
            # Mantener informaci√≥n de color pero mejorar detalles
            hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
            hsv[:, :, 2] = cv2.addWeighted(hsv[:, :, 2], 0.7, img_back, 0.3, 0)
            enhanced_color = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)
            return enhanced_color
        else:
            return img_back
    
    def _normalize_image(self, img: np.ndarray) -> np.ndarray:
        """
        Normalizaci√≥n espec√≠fica para hologramas
        
        Args:
            img: Imagen a normalizar
            
        Returns:
            Imagen normalizada
        """
        if img.dtype != np.float32:
            img = img.astype(np.float32)
        
        # Normalizaci√≥n por canal
        if len(img.shape) == 3:
            # Para im√°genes a color, normalizar cada canal independientemente
            normalized = np.zeros_like(img)
            for i in range(img.shape[2]):
                channel = img[:, :, i]
                # Normalizaci√≥n robusta usando percentiles para evitar outliers
                p2, p98 = np.percentile(channel, (2, 98))
                normalized[:, :, i] = np.clip((channel - p2) / (p98 - p2), 0, 1)
        else:
            # Para escala de grises
            p2, p98 = np.percentile(img, (2, 98))
            normalized = np.clip((img - p2) / (p98 - p2), 0, 1)
        
        return normalized
    
    def _adaptive_contrast_enhancement(self, img: np.ndarray) -> np.ndarray:
        """
        Mejora de contraste adaptativo
        
        Args:
            img: Imagen normalizada
            
        Returns:
            Imagen con contraste mejorado
        """
        # Convertir a uint8 para CLAHE
        if img.dtype == np.float32:
            img_uint8 = (img * 255).astype(np.uint8)
        else:
            img_uint8 = img
        
        if len(img.shape) == 3:
            # Para im√°genes a color, aplicar CLAHE en espacio LAB
            lab = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2LAB)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            lab[:, :, 0] = clahe.apply(lab[:, :, 0])
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        else:
            # Para escala de grises
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            enhanced = clahe.apply(img_uint8)
        
        # Convertir de vuelta a float32 normalizado
        return enhanced.astype(np.float32) / 255.0
    
    def load_dataset(self, dataset_path: str = "dataset", test_size: float = 0.2, 
                    random_state: int = 42, apply_hologram_enhancement: bool = True) -> Dict:
        """
        Cargar y preprocesar todo el dataset
        
        Args:
            dataset_path: Ruta del dataset
            test_size: Proporci√≥n del conjunto de prueba
            random_state: Semilla para reproducibilidad
            apply_hologram_enhancement: Si aplicar mejoras hologr√°ficas
            
        Returns:
            Diccionario con datos preprocesados
        """
        print("üîÑ Cargando y preprocesando dataset...")
        
        # Cargar rutas de archivos y etiquetas
        image_paths = []
        labels = []
        
        dataset_path = Path(dataset_path)
        classes = ["SCD", "Healthy"]
        
        for class_name in classes:
            class_path = dataset_path / class_name
            if class_path.exists():
                image_files = list(class_path.glob("*.png"))
                print(f"   ‚îî‚îÄ {class_name}: {len(image_files)} im√°genes")
                
                for img_path in image_files:
                    image_paths.append(str(img_path))
                    labels.append(class_name)
        
        # Codificar etiquetas
        labels_encoded = self.label_encoder.fit_transform(labels)
        
        # Divisi√≥n estratificada
        X_train_paths, X_test_paths, y_train, y_test = train_test_split(
            image_paths, labels_encoded, test_size=test_size, 
            random_state=random_state, stratify=labels_encoded
        )
        
        print(f"\nüìä Divisi√≥n del dataset:")
        print(f"   ‚Ä¢ Entrenamiento: {len(X_train_paths)} im√°genes")
        print(f"   ‚Ä¢ Prueba: {len(X_test_paths)} im√°genes")
        
        # Preprocesar im√°genes
        print("\nüîÑ Preprocesando im√°genes...")
        
        X_train = []
        X_test = []
        
        # Procesar conjunto de entrenamiento
        print("   ‚îî‚îÄ Procesando conjunto de entrenamiento...")
        for i, path in enumerate(X_train_paths):
            if i % 20 == 0:
                print(f"      Progreso: {i+1}/{len(X_train_paths)}")
            processed_img = self.load_and_preprocess_image(path, apply_hologram_enhancement)
            X_train.append(processed_img)
        
        # Procesar conjunto de prueba
        print("   ‚îî‚îÄ Procesando conjunto de prueba...")
        for i, path in enumerate(X_test_paths):
            if i % 10 == 0:
                print(f"      Progreso: {i+1}/{len(X_test_paths)}")
            processed_img = self.load_and_preprocess_image(path, apply_hologram_enhancement)
            X_test.append(processed_img)
        
        # Convertir a arrays numpy
        X_train = np.array(X_train)
        X_test = np.array(X_test)
        y_train = np.array(y_train)
        y_test = np.array(y_test)
        
        # Guardar estad√≠sticas de preprocesamiento
        self.preprocessing_stats = {
            'target_size': self.target_size,
            'n_train': len(X_train),
            'n_test': len(X_test),
            'n_classes': len(self.label_encoder.classes_),
            'classes': self.label_encoder.classes_.tolist(),
            'train_distribution': {
                class_name: int(np.sum(y_train == i)) 
                for i, class_name in enumerate(self.label_encoder.classes_)
            },
            'test_distribution': {
                class_name: int(np.sum(y_test == i)) 
                for i, class_name in enumerate(self.label_encoder.classes_)
            },
            'hologram_enhancement': apply_hologram_enhancement
        }
        
        print(f"\n‚úÖ Preprocesamiento completado!")
        print(f"   ‚Ä¢ Forma X_train: {X_train.shape}")
        print(f"   ‚Ä¢ Forma X_test: {X_test.shape}")
        print(f"   ‚Ä¢ Forma y_train: {y_train.shape}")
        print(f"   ‚Ä¢ Forma y_test: {y_test.shape}")
        
        return {
            'X_train': X_train,
            'X_test': X_test,
            'y_train': y_train,
            'y_test': y_test,
            'train_paths': X_train_paths,
            'test_paths': X_test_paths,
            'label_encoder': self.label_encoder,
            'preprocessing_stats': self.preprocessing_stats
        }
    
    def visualize_preprocessing_effects(self, original_img_path: str, save_path: str = "preprocessing_comparison.png"):
        """
        Visualizar los efectos del preprocesamiento
        
        Args:
            original_img_path: Ruta de una imagen original
            save_path: Ruta donde guardar la comparaci√≥n
        """
        print("üñºÔ∏è Generando visualizaci√≥n de efectos de preprocesamiento...")
        
        # Cargar imagen original
        original_img = cv2.imread(original_img_path)
        original_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
        
        # Aplicar diferentes etapas del preprocesamiento
        step1_resized = self._smart_resize(original_rgb)
        step2_enhanced = self._hologram_enhancement(step1_resized)
        step3_normalized = self._normalize_image(step2_enhanced)
        step4_contrast = self._adaptive_contrast_enhancement(step3_normalized)
        
        # Crear visualizaci√≥n
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Efectos del Pipeline de Preprocesamiento', fontsize=16, fontweight='bold')
        
        # Imagen original (redimensionada para visualizaci√≥n)
        original_display = cv2.resize(original_rgb, (400, 300))
        axes[0, 0].imshow(original_display)
        axes[0, 0].set_title('Original\n(Redimensionada para display)')
        axes[0, 0].axis('off')
        
        # Redimensionado inteligente
        axes[0, 1].imshow(step1_resized)
        axes[0, 1].set_title(f'Redimensionado Inteligente\n{step1_resized.shape[:2]}')
        axes[0, 1].axis('off')
        
        # Mejoras hologr√°ficas
        axes[0, 2].imshow(step2_enhanced)
        axes[0, 2].set_title('Mejoras Hologr√°ficas\n(Realce de patrones)')
        axes[0, 2].axis('off')
        
        # Normalizaci√≥n
        axes[1, 0].imshow(step3_normalized)
        axes[1, 0].set_title('Normalizaci√≥n\n(Percentiles 2-98)')
        axes[1, 0].axis('off')
        
        # Mejora de contraste
        axes[1, 1].imshow(step4_contrast)
        axes[1, 1].set_title('Contraste Adaptativo\n(CLAHE)')
        axes[1, 1].axis('off')
        
        # Histograma de comparaci√≥n
        axes[1, 2].hist(original_rgb.flatten(), bins=50, alpha=0.7, label='Original', color='red', density=True)
        axes[1, 2].hist((step4_contrast * 255).astype(np.uint8).flatten(), bins=50, alpha=0.7, label='Procesada', color='blue', density=True)
        axes[1, 2].set_title('Comparaci√≥n de Histogramas')
        axes[1, 2].set_xlabel('Intensidad de P√≠xel')
        axes[1, 2].set_ylabel('Densidad')
        axes[1, 2].legend()
        axes[1, 2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.show()
        
        print(f"‚úÖ Visualizaci√≥n guardada en: {save_path}")
    
    def save_preprocessing_config(self, filepath: str = "preprocessing_config.json"):
        """
        Guardar configuraci√≥n de preprocesamiento
        
        Args:
            filepath: Ruta donde guardar la configuraci√≥n
        """
        config = {
            'target_size': self.target_size,
            'preprocessing_stats': self.preprocessing_stats
        }
        
        with open(filepath, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"üíæ Configuraci√≥n guardada en: {filepath}")

def main():
    """
    Funci√≥n principal para demostrar el pipeline de preprocesamiento
    """
    print("üî¨ PIPELINE DE PREPROCESAMIENTO PARA HOLOGRAMAS")
    print("=" * 60)
    
    # Inicializar preprocesador
    preprocessor = HologramPreprocessor(target_size=(512, 512))
    
    # Cargar y preprocesar dataset completo
    dataset = preprocessor.load_dataset(
        dataset_path="dataset",
        test_size=0.2,
        random_state=42,
        apply_hologram_enhancement=True
    )
    
    # Mostrar estad√≠sticas
    print("\nüìä ESTAD√çSTICAS DEL DATASET PREPROCESADO:")
    print("=" * 50)
    stats = dataset['preprocessing_stats']
    print(f"Tama√±o objetivo: {stats['target_size']}")
    print(f"Total de clases: {stats['n_classes']}")
    print(f"Clases: {', '.join(stats['classes'])}")
    print(f"\nDistribuci√≥n de entrenamiento:")
    for class_name, count in stats['train_distribution'].items():
        print(f"   {class_name}: {count} im√°genes")
    print(f"\nDistribuci√≥n de prueba:")
    for class_name, count in stats['test_distribution'].items():
        print(f"   {class_name}: {count} im√°genes")
    
    # Generar visualizaci√≥n de una imagen de ejemplo
    sample_paths = dataset['train_paths'][:2]  # Tomar dos ejemplos
    for i, path in enumerate(sample_paths):
        save_path = f"preprocessing_example_{i+1}.png"
        preprocessor.visualize_preprocessing_effects(path, save_path)
    
    # Guardar configuraci√≥n
    preprocessor.save_preprocessing_config()
    
    # Guardar dataset preprocesado
    print("\nüíæ Guardando dataset preprocesado...")
    np.savez_compressed(
        'preprocessed_dataset.npz',
        X_train=dataset['X_train'],
        X_test=dataset['X_test'],
        y_train=dataset['y_train'],
        y_test=dataset['y_test']
    )
    
    print("‚úÖ Pipeline de preprocesamiento completado!")
    print("üìÅ Archivos generados:")
    print("   ‚Ä¢ preprocessing_example_1.png")
    print("   ‚Ä¢ preprocessing_example_2.png") 
    print("   ‚Ä¢ preprocessing_config.json")
    print("   ‚Ä¢ preprocessed_dataset.npz")

if __name__ == "__main__":
    main()
```

Voy a corregir los errores de tipos en el c√≥digo:

```python
        # Cargar rutas de archivos y etiquetas
        image_paths = []
        labels = []
        
        dataset_path = Path(dataset_path)
        classes = ["SCD", "Healthy"]
        
        for class_name in classes:
            class_path = dataset_path / class_name

->

        # Cargar rutas de archivos y etiquetas
        image_paths = []
        labels = []
        
        dataset_path_obj = Path(dataset_path)
        classes = ["SCD", "Healthy"]
        
        for class_name in classes:
            class_path = dataset_path_obj / class_name
```

Perfecto, los errores de tipos espec√≠ficos fueron corregidos. Los errores de importaci√≥n restantes no son problem√°ticos ya que las librer√≠as est√°n instaladas. Ahora ejecutemos el pipeline de preprocesamiento:

¬°Excelente! El pipeline de preprocesamiento se complet√≥ exitosamente. Vamos a marcar la tarea como completada y verificar los resultados:

## üéØ **PIPELINE DE PREPROCESAMIENTO COMPLETADO**

¬°Excelente trabajo! El pipeline de preprocesamiento se ejecut√≥ perfectamente. Aqu√≠ est√°n los **resultados clave**:

### üìä **Transformaci√≥n del Dataset:**

**Antes del Preprocesamiento:**
- 1.25 GB de espacio
- 196 im√°genes de 3000√ó4000 p√≠xeles
- Sin optimizaciones

**Despu√©s del Preprocesamiento:**
- 69 MB de espacio (**95% de reducci√≥n!**)
- 196 im√°genes de 512√ó512 p√≠xeles
- Optimizadas para hologramas

### üîß **T√©cnicas Aplicadas:**

1. **Redimensionado Inteligente:** Preserva proporciones con padding
2. **Mejoras Hologr√°ficas:** Filtros FFT + realce de patrones de interferencia
3. **Normalizaci√≥n Robusta:** Usando percentiles 2-98 para evitar outliers
4. **Contraste Adaptativo:** CLAHE en espacio LAB para mejor distribuci√≥n

### üìà **Divisi√≥n Estratificada:**
- **Entrenamiento:** 156 im√°genes (Healthy: 90, SCD: 66)
- **Prueba:** 40 im√°genes (Healthy: 23, SCD: 17)
- **Balance mantenido:** ~58% Healthy, ~42% SCD

### üìÅ **Archivos Generados:**
‚úÖ `preprocessed_dataset.npz` - Dataset optimizado (69MB)
‚úÖ `preprocessing_example_1.png` - Visualizaci√≥n de efectos
‚úÖ `preprocessing_example_2.png` - Comparaci√≥n paso a paso
‚úÖ `preprocessing_config.json` - Configuraci√≥n y estad√≠sticas

### üöÄ **Pr√≥ximo Paso Cr√≠tico:**
Con solo **156 im√°genes de entrenamiento**, necesitamos implementar **Data Augmentation agresiva** para generar variaciones sint√©ticas y prevenir overfitting.

¬øQuieres que contin√∫e implementando las estrategias de Data Augmentation? Esto incluir√°:
- Rotaciones y flips espec√≠ficos para hologramas
- Variaciones de contraste y brillo
- Transformaciones el√°sticas
- Filtros de ruido y blur
- T√©cnicas avanzadas como Mixup y CutMix

---

**User**

continua

---

**Cursor**

¬°Perfecto! Continuemos con las estrategias de Data Augmentation. Marcar√© la tarea correspondiente como en progreso e implementar√© t√©cnicas especializadas para hologramas.

```python
#!/usr/bin/env python3
"""
Data Augmentation Especializado para Hologramas de Gl√≥bulos Sangu√≠neos
Proyecto: Clasificaci√≥n de c√©lulas sanas vs SCD

Este m√≥dulo implementa t√©cnicas avanzadas de data augmentation espec√≠ficamente
dise√±adas para hologramas, maximizando la variabilidad del dataset sin perder
caracter√≠sticas importantes para la clasificaci√≥n.
"""

import numpy as np
import cv2
import random
from typing import Tuple, List, Dict, Callable, Union
import matplotlib.pyplot as plt
from scipy import ndimage
from skimage import transform, filters, exposure
import albumentations as A
from albumentations.pytorch import ToTensorV2
import warnings
warnings.filterwarnings('ignore')

class HologramAugmentator:
    """
    Clase para data augmentation especializado en hologramas
    """
    
    def __init__(self, 
                 augmentation_factor: int = 8,
                 preserve_hologram_features: bool = True,
                 apply_advanced_techniques: bool = True):
        """
        Inicializar el augmentador
        
        Args:
            augmentation_factor: Factor de multiplicaci√≥n del dataset
            preserve_hologram_features: Si preservar caracter√≠sticas hologr√°ficas
            apply_advanced_techniques: Si aplicar t√©cnicas avanzadas (Mixup, CutMix)
        """
        self.augmentation_factor = augmentation_factor
        self.preserve_hologram_features = preserve_hologram_features
        self.apply_advanced_techniques = apply_advanced_techniques
        self.augmentation_stats = {}
        
        # Configurar pipelines de augmentation
        self.setup_augmentation_pipelines()
    
    def setup_augmentation_pipelines(self):
        """Configurar diferentes pipelines de augmentation"""
        
        # Pipeline b√°sico - transformaciones geom√©tricas
        self.basic_augmentations = A.Compose([
            A.RandomRotate90(p=0.5),
            A.Flip(p=0.5),
            A.ShiftScaleRotate(
                shift_limit=0.1, 
                scale_limit=0.1, 
                rotate_limit=15, 
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.8
            ),
            A.ElasticTransform(
                alpha=50, 
                sigma=5, 
                alpha_affine=5,
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.3
            )
        ])
        
        # Pipeline de mejoras visuales - preserva patrones hologr√°ficos
        self.visual_augmentations = A.Compose([
            A.RandomBrightnessContrast(
                brightness_limit=0.15, 
                contrast_limit=0.15, 
                p=0.7
            ),
            A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),
            A.RandomGamma(gamma_limit=(80, 120), p=0.4),
            A.GaussNoise(var_limit=(10, 30), p=0.3),
            A.Blur(blur_limit=3, p=0.2)
        ])
        
        # Pipeline avanzado - t√©cnicas espec√≠ficas para hologramas
        self.hologram_augmentations = A.Compose([
            A.OpticalDistortion(
                distort_limit=0.1, 
                shift_limit=0.05,
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.3
            ),
            A.GridDistortion(
                num_steps=5, 
                distort_limit=0.1,
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.3
            ),
            A.GaussianBlur(blur_limit=(1, 3), p=0.2),
            A.MotionBlur(blur_limit=3, p=0.2)
        ])
        
        # Pipeline combinado
        self.combined_pipeline = A.Compose([
            A.OneOf([
                self.basic_augmentations,
                self.visual_augmentations,
                self.hologram_augmentations
            ], p=1.0),
            A.OneOf([
                A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),
                A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1),
                A.NoOp()
            ], p=0.5)
        ])
    
    def frequency_domain_augmentation(self, image: np.ndarray, intensity: float = 0.1) -> np.ndarray:
        """
        Augmentation en el dominio de frecuencia espec√≠fico para hologramas
        
        Args:
            image: Imagen de entrada
            intensity: Intensidad de la transformaci√≥n
            
        Returns:
            Imagen transformada
        """
        if len(image.shape) == 3:
            # Para im√°genes a color, trabajar con canal de luminancia
            gray = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
        else:
            gray = (image * 255).astype(np.uint8)
        
        # Aplicar FFT
        f_transform = np.fft.fft2(gray)
        f_shift = np.fft.fftshift(f_transform)
        
        # Crear perturbaci√≥n en el dominio de frecuencia
        rows, cols = gray.shape
        crow, ccol = rows // 2, cols // 2
        
        # Generar ruido aleatorio en frecuencias espec√≠ficas
        noise_mask = np.random.normal(1.0, intensity, (rows, cols))
        
        # Aplicar m√°scara para preservar frecuencias centrales (caracter√≠sticas principales)
        preservation_radius = min(rows, cols) // 8
        y, x = np.ogrid[:rows, :cols]
        center_mask = (x - ccol) ** 2 + (y - crow) ** 2 <= preservation_radius ** 2
        noise_mask[center_mask] = 1.0
        
        # Aplicar perturbaci√≥n
        f_shift_augmented = f_shift * noise_mask
        
        # Transformada inversa
        f_ishift = np.fft.ifftshift(f_shift_augmented)
        img_back = np.fft.ifft2(f_ishift)
        img_back = np.real(img_back)
        
        # Normalizar y convertir de vuelta
        img_back = np.clip(img_back, 0, 255).astype(np.uint8)
        
        if len(image.shape) == 3:
            # Reconstituir imagen a color
            result = image.copy()
            # Aplicar transformaci√≥n al canal de luminancia en espacio HSV
            hsv = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2HSV)
            hsv[:, :, 2] = img_back
            result = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB).astype(np.float32) / 255.0
            return result
        else:
            return img_back.astype(np.float32) / 255.0
    
    def interference_pattern_augmentation(self, image: np.ndarray) -> np.ndarray:
        """
        Augmentation que simula variaciones en patrones de interferencia
        
        Args:
            image: Imagen de entrada
            
        Returns:
            Imagen con patrones de interferencia modificados
        """
        h, w = image.shape[:2]
        
        # Generar patr√≥n sinusoidal aleatorio
        frequency = random.uniform(0.5, 2.0)
        phase = random.uniform(0, 2 * np.pi)
        amplitude = random.uniform(0.02, 0.08)
        
        # Crear coordenadas
        x = np.linspace(0, 2 * np.pi * frequency, w)
        y = np.linspace(0, 2 * np.pi * frequency, h)
        X, Y = np.meshgrid(x, y)
        
        # Generar patr√≥n de interferencia
        interference = amplitude * np.sin(X + phase) * np.sin(Y + phase)
        
        # Aplicar el patr√≥n
        if len(image.shape) == 3:
            interference = np.expand_dims(interference, axis=2)
            interference = np.repeat(interference, 3, axis=2)
        
        augmented = image + interference
        return np.clip(augmented, 0, 1)
    
    def mixup_augmentation(self, image1: np.ndarray, image2: np.ndarray, 
                          label1: int, label2: int, alpha: float = 0.2) -> Tuple[np.ndarray, float]:
        """
        Implementaci√≥n de Mixup para hologramas
        
        Args:
            image1, image2: Im√°genes a mezclar
            label1, label2: Etiquetas correspondientes
            alpha: Par√°metro de la distribuci√≥n Beta
            
        Returns:
            Imagen mezclada y etiqueta interpolada
        """
        if alpha > 0:
            lam = np.random.beta(alpha, alpha)
        else:
            lam = 1
        
        mixed_image = lam * image1 + (1 - lam) * image2
        mixed_label = lam * label1 + (1 - lam) * label2
        
        return mixed_image, mixed_label
    
    def cutmix_augmentation(self, image1: np.ndarray, image2: np.ndarray,
                           label1: int, label2: int, alpha: float = 1.0) -> Tuple[np.ndarray, float]:
        """
        Implementaci√≥n de CutMix para hologramas
        
        Args:
            image1, image2: Im√°genes a mezclar
            label1, label2: Etiquetas correspondientes
            alpha: Par√°metro para determinar el tama√±o del corte
            
        Returns:
            Imagen con CutMix y etiqueta ajustada
        """
        h, w = image1.shape[:2]
        
        # Generar par√°metros del corte
        lam = np.random.beta(alpha, alpha)
        cut_rat = np.sqrt(1. - lam)
        cut_w = int(w * cut_rat)
        cut_h = int(h * cut_rat)
        
        # Posici√≥n aleatoria del corte
        cx = np.random.randint(w)
        cy = np.random.randint(h)
        
        bbx1 = np.clip(cx - cut_w // 2, 0, w)
        bby1 = np.clip(cy - cut_h // 2, 0, h)
        bbx2 = np.clip(cx + cut_w // 2, 0, w)
        bby2 = np.clip(cy + cut_h // 2, 0, h)
        
        # Crear imagen mezclada
        mixed_image = image1.copy()
        mixed_image[bby1:bby2, bbx1:bbx2] = image2[bby1:bby2, bbx1:bbx2]
        
        # Ajustar etiqueta seg√∫n el √°rea mezclada
        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (w * h))
        mixed_label = lam * label1 + (1 - lam) * label2
        
        return mixed_image, mixed_label
    
    def augment_single_image(self, image: np.ndarray, label: int = None) -> List[Tuple[np.ndarray, int]]:
        """
        Aplicar m√∫ltiples augmentations a una sola imagen
        
        Args:
            image: Imagen original
            label: Etiqueta de la imagen
            
        Returns:
            Lista de im√°genes augmentadas con sus etiquetas
        """
        augmented_images = []
        
        # Imagen original
        augmented_images.append((image, label))
        
        # Aplicar augmentations b√°sicas m√∫ltiples veces
        for i in range(self.augmentation_factor - 1):
            
            # Seleccionar tipo de augmentation
            aug_type = random.choice(['basic', 'visual', 'hologram', 'combined'])
            
            # Convertir a formato uint8 para albumentations
            img_uint8 = (image * 255).astype(np.uint8)
            
            if aug_type == 'basic':
                augmented = self.basic_augmentations(image=img_uint8)['image']
            elif aug_type == 'visual':
                augmented = self.visual_augmentations(image=img_uint8)['image']
            elif aug_type == 'hologram':
                augmented = self.hologram_augmentations(image=img_uint8)['image']
            else:
                augmented = self.combined_pipeline(image=img_uint8)['image']
            
            # Convertir de vuelta a float32
            augmented = augmented.astype(np.float32) / 255.0
            
            # Aplicar augmentations espec√≠ficas para hologramas si est√° habilitado
            if self.preserve_hologram_features:
                if random.random() < 0.3:
                    augmented = self.frequency_domain_augmentation(augmented)
                if random.random() < 0.2:
                    augmented = self.interference_pattern_augmentation(augmented)
            
            augmented_images.append((augmented, label))
        
        return augmented_images
    
    def augment_dataset(self, X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        Aplicar data augmentation a todo el dataset
        
        Args:
            X: Array de im√°genes
            y: Array de etiquetas
            
        Returns:
            Dataset augmentado
        """
        print(f"üîÑ Aplicando data augmentation (factor: {self.augmentation_factor})...")
        print(f"   Dataset original: {X.shape[0]} im√°genes")
        
        augmented_X = []
        augmented_y = []
        
        # Procesar cada imagen
        for i, (image, label) in enumerate(zip(X, y)):
            if i % 20 == 0:
                print(f"   Progreso: {i+1}/{len(X)}")
            
            # Aplicar augmentations b√°sicas
            aug_images = self.augment_single_image(image, label)
            
            for aug_img, aug_label in aug_images:
                augmented_X.append(aug_img)
                augmented_y.append(aug_label)
        
        # Aplicar t√©cnicas avanzadas si est√° habilitado
        if self.apply_advanced_techniques:
            print("   ‚îî‚îÄ Aplicando t√©cnicas avanzadas (Mixup, CutMix)...")
            advanced_X, advanced_y = self._apply_advanced_augmentations(augmented_X, augmented_y)
            augmented_X.extend(advanced_X)
            augmented_y.extend(advanced_y)
        
        # Convertir a arrays numpy
        X_augmented = np.array(augmented_X)
        y_augmented = np.array(augmented_y)
        
        # Mezclar el dataset
        indices = np.random.permutation(len(X_augmented))
        X_augmented = X_augmented[indices]
        y_augmented = y_augmented[indices]
        
        print(f"‚úÖ Data augmentation completado!")
        print(f"   Dataset augmentado: {X_augmented.shape[0]} im√°genes")
        print(f"   Factor de aumento: {X_augmented.shape[0] / X.shape[0]:.1f}x")
        
        # Guardar estad√≠sticas
        self.augmentation_stats = {
            'original_size': int(X.shape[0]),
            'augmented_size': int(X_augmented.shape[0]),
            'augmentation_factor': self.augmentation_factor,
            'multiplication_achieved': float(X_augmented.shape[0] / X.shape[0]),
            'advanced_techniques_used': self.apply_advanced_techniques,
            'hologram_features_preserved': self.preserve_hologram_features
        }
        
        return X_augmented, y_augmented
    
    def _apply_advanced_augmentations(self, X_list: List[np.ndarray], 
                                    y_list: List[int], 
                                    n_samples: int = None) -> Tuple[List[np.ndarray], List[int]]:
        """
        Aplicar t√©cnicas avanzadas como Mixup y CutMix
        
        Args:
            X_list: Lista de im√°genes
            y_list: Lista de etiquetas
            n_samples: N√∫mero de muestras a generar
            
        Returns:
            Im√°genes y etiquetas generadas con t√©cnicas avanzadas
        """
        if n_samples is None:
            n_samples = len(X_list) // 4  # 25% del dataset con t√©cnicas avanzadas
        
        advanced_X = []
        advanced_y = []
        
        for _ in range(n_samples):
            # Seleccionar dos im√°genes aleatorias
            idx1, idx2 = random.sample(range(len(X_list)), 2)
            img1, label1 = X_list[idx1], y_list[idx1]
            img2, label2 = X_list[idx2], y_list[idx2]
            
            # Aplicar Mixup o CutMix aleatoriamente
            if random.random() < 0.5:
                # Mixup
                mixed_img, mixed_label = self.mixup_augmentation(img1, img2, label1, label2)
            else:
                # CutMix
                mixed_img, mixed_label = self.cutmix_augmentation(img1, img2, label1, label2)
            
            advanced_X.append(mixed_img)
            advanced_y.append(mixed_label)
        
        return advanced_X, advanced_y
    
    def visualize_augmentations(self, image: np.ndarray, label: int = None, 
                               save_path: str = "augmentation_examples.png"):
        """
        Visualizar diferentes tipos de augmentation aplicados a una imagen
        
        Args:
            image: Imagen original
            label: Etiqueta de la imagen
            save_path: Ruta donde guardar la visualizaci√≥n
        """
        print("üñºÔ∏è Generando visualizaci√≥n de data augmentations...")
        
        # Generar ejemplos de diferentes augmentations
        img_uint8 = (image * 255).astype(np.uint8)
        
        # Aplicar diferentes pipelines
        basic_aug = self.basic_augmentations(image=img_uint8)['image']
        visual_aug = self.visual_augmentations(image=img_uint8)['image']
        hologram_aug = self.hologram_augmentations(image=img_uint8)['image']
        combined_aug = self.combined_pipeline(image=img_uint8)['image']
        
        # Aplicar augmentations espec√≠ficas
        freq_aug = (self.frequency_domain_augmentation(image) * 255).astype(np.uint8)
        interference_aug = (self.interference_pattern_augmentation(image) * 255).astype(np.uint8)
        
        # Crear visualizaci√≥n
        fig, axes = plt.subplots(2, 4, figsize=(20, 10))
        fig.suptitle('Ejemplos de Data Augmentation para Hologramas', fontsize=16, fontweight='bold')
        
        images = [
            (img_uint8, "Original"),
            (basic_aug, "Transformaciones\nGeom√©tricas"),
            (visual_aug, "Mejoras\nVisuales"),
            (hologram_aug, "Augmentations\nHologr√°ficas"),
            (combined_aug, "Pipeline\nCombinado"),
            (freq_aug, "Dominio de\nFrecuencia"),
            (interference_aug, "Patrones de\nInterferencia"),
            (img_uint8, "Reservado para\nT√©cnicas Avanzadas")
        ]
        
        for idx, (img, title) in enumerate(images):
            row = idx // 4
            col = idx % 4
            axes[row, col].imshow(img)
            axes[row, col].set_title(title, fontsize=12)
            axes[row, col].axis('off')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.show()
        
        print(f"‚úÖ Visualizaci√≥n guardada en: {save_path}")
    
    def save_augmentation_config(self, filepath: str = "augmentation_config.json"):
        """
        Guardar configuraci√≥n de augmentation
        
        Args:
            filepath: Ruta donde guardar la configuraci√≥n
        """
        import json
        
        config = {
            'augmentation_factor': self.augmentation_factor,
            'preserve_hologram_features': self.preserve_hologram_features,
            'apply_advanced_techniques': self.apply_advanced_techniques,
            'augmentation_stats': self.augmentation_stats
        }
        
        with open(filepath, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"üíæ Configuraci√≥n de augmentation guardada en: {filepath}")

def main():
    """
    Funci√≥n principal para demostrar el data augmentation
    """
    print("üî¨ DATA AUGMENTATION PARA HOLOGRAMAS")
    print("=" * 50)
    
    # Cargar dataset preprocesado
    print("üìÅ Cargando dataset preprocesado...")
    data = np.load('preprocessed_dataset.npz')
    X_train, y_train = data['X_train'], data['y_train']
    X_test, y_test = data['X_test'], data['y_test']
    
    print(f"   Dataset original: {X_train.shape[0]} im√°genes de entrenamiento")
    
    # Inicializar augmentador
    augmentator = HologramAugmentator(
        augmentation_factor=8,
        preserve_hologram_features=True,
        apply_advanced_techniques=True
    )
    
    # Generar visualizaci√≥n de augmentations
    sample_image = X_train[0]
    sample_label = y_train[0]
    augmentator.visualize_augmentations(sample_image, sample_label)
    
    # Aplicar data augmentation al dataset de entrenamiento
    X_train_augmented, y_train_augmented = augmentator.augment_dataset(X_train, y_train)
    
    # Mostrar estad√≠sticas
    print(f"\nüìä ESTAD√çSTICAS DE DATA AUGMENTATION:")
    print("=" * 50)
    stats = augmentator.augmentation_stats
    print(f"Dataset original: {stats['original_size']} im√°genes")
    print(f"Dataset augmentado: {stats['augmented_size']} im√°genes")
    print(f"Factor configurado: {stats['augmentation_factor']}x")
    print(f"Factor real alcanzado: {stats['multiplication_achieved']:.1f}x")
    print(f"T√©cnicas avanzadas: {'‚úÖ' if stats['advanced_techniques_used'] else '‚ùå'}")
    print(f"Preservaci√≥n hologr√°fica: {'‚úÖ' if stats['hologram_features_preserved'] else '‚ùå'}")
    
    # Guardar dataset augmentado
    print(f"\nüíæ Guardando dataset augmentado...")
    np.savez_compressed(
        'augmented_dataset.npz',
        X_train=X_train_augmented,
        y_train=y_train_augmented,
        X_test=X_test,
        y_test=y_test
    )
    
    # Guardar configuraci√≥n
    augmentator.save_augmentation_config()
    
    print("‚úÖ Data augmentation completado!")
    print("üìÅ Archivos generados:")
    print("   ‚Ä¢ augmentation_examples.png")
    print("   ‚Ä¢ augmented_dataset.npz")
    print("   ‚Ä¢ augmentation_config.json")

if __name__ == "__main__":
    main()
```

Primero voy a instalar las librer√≠as faltantes y corregir los errores de tipo:

Ahora voy a corregir los errores de tipo donde se pasa None en lugar de int:

```python
    def augment_single_image(self, image: np.ndarray, label: int = None) -> List[Tuple[np.ndarray, int]]:
        """
        Aplicar m√∫ltiples augmentations a una sola imagen
        
        Args:
            image: Imagen original
            label: Etiqueta de la imagen
            
        Returns:
            Lista de im√°genes augmentadas con sus etiquetas
        """
        augmented_images = []
        
        # Imagen original
        augmented_images.append((image, label))

->

    def augment_single_image(self, image: np.ndarray, label: int = 0) -> List[Tuple[np.ndarray, int]]:
        """
        Aplicar m√∫ltiples augmentations a una sola imagen
        
        Args:
            image: Imagen original
            label: Etiqueta de la imagen
            
        Returns:
            Lista de im√°genes augmentadas con sus etiquetas
        """
        augmented_images = []
        
        # Imagen original
        augmented_images.append((image, label))
```

```python
    def visualize_augmentations(self, image: np.ndarray, label: int = None, 
                               save_path: str = "augmentation_examples.png"):

->

    def visualize_augmentations(self, image: np.ndarray, label: int = 0, 
                               save_path: str = "augmentation_examples.png"):
```

```python
augmentator.visualize_augmentations(sample_image, sample_label)
```

```python
     # Generar visualizaci√≥n de augmentations
     sample_image = X_train[0]
     sample_label = y_train[0]
     augmentator.visualize_augmentations(sample_image, sample_label)

->

     # Generar visualizaci√≥n de augmentations
     sample_image = X_train[0]
     sample_label = int(y_train[0])
     augmentator.visualize_augmentations(sample_image, sample_label)
```

Los errores de importaci√≥n no son problem√°ticos ya que las librer√≠as est√°n instaladas. Voy a ejecutar el script de data augmentation:

Voy a corregir el error de indentaci√≥n:

```python
     # Generar visualizaci√≥n de augmentations
     sample_image = X_train[0]
      sample_label = int(y_train[0])
     augmentator.visualize_augmentations(sample_image, sample_label)

->

     # Generar visualizaci√≥n de augmentations
     sample_image = X_train[0]
     sample_label = int(y_train[0])
     augmentator.visualize_augmentations(sample_image, sample_label)
```

```python
    )
    
    # Generar visualizaci√≥n de augmentations
    sample_image = X_train[0]
    sample_label = int(y_train[0])
    augmentator.visualize_augmentations(sample_image, sample_label)
    
    # Aplicar data augmentation al dataset de entrenamiento
```

El problema es que estamos importando PyTorch que no necesitamos. Voy a quitar esa importaci√≥n:

```python
import numpy as np
import cv2
import random
from typing import Tuple, List, Dict, Callable, Union
import matplotlib.pyplot as plt
from scipy import ndimage
from skimage import transform, filters, exposure
import albumentations as A
import warnings
warnings.filterwarnings('ignore')
```

Perfecto, ahora intentemos ejecutar el script:

Hay un problema con la API de Albumentations. Voy a corregir los nombres de las transformaciones:

```python
        # Pipeline b√°sico - transformaciones geom√©tricas
        self.basic_augmentations = A.Compose([
            A.RandomRotate90(p=0.5),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.3),
            A.ShiftScaleRotate(
                shift_limit=0.1, 
                scale_limit=0.1, 
                rotate_limit=15, 
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.8
            ),
            A.ElasticTransform(
                alpha=50, 
                sigma=5, 
                alpha_affine=5,
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.3
            )
        ])
        
        # Pipeline de mejoras visuales - preserva patrones hologr√°ficos
        self.visual_augmentations = A.Compose([
            A.RandomBrightnessContrast(
                brightness_limit=0.15, 
                contrast_limit=0.15, 
                p=0.7
            ),
            A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),
            A.RandomGamma(gamma_limit=(80, 120), p=0.4),
            A.GaussNoise(var_limit=(10, 30), p=0.3),
            A.Blur(blur_limit=3, p=0.2)
        ])
        
        # Pipeline avanzado - t√©cnicas espec√≠ficas para hologramas
        self.hologram_augmentations = A.Compose([
            A.OpticalDistortion(
                distort_limit=0.1, 
                shift_limit=0.05,
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.3
            ),
            A.GridDistortion(
                num_steps=5, 
                distort_limit=0.1,
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.3
            ),
            A.GaussianBlur(blur_limit=(1, 3), p=0.2),
            A.MotionBlur(blur_limit=3, p=0.2)
        ])
```

Ahora intentemos ejecutar el script nuevamente:

