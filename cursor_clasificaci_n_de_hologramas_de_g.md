# ClasificaciÃ³n de hologramas de glÃ³bulos sanguÃ­neos
_Exported on 7/15/2025 at 00:06:36 GMT-5 from Cursor (1.2.4)_

---

**User**

Quiero que analices la carpeta dataset, ahi hay hologramas de globulos sanguineos, mi objetivo es realizar un clasificador para identificar sanos y enfermos, como podrÃ¡s ver una de las limitaciones es que tenemos que entrenar con apenas 200 imagenes y obtener buenos resultados sin overfitting, analiza el dataset y hagamos un plan de trabajo

---

**Cursor**

Â¡Perfecto! Voy a analizar el dataset de hologramas de glÃ³bulos sanguÃ­neos para ayudarte a crear un clasificador efectivo con pocas imÃ¡genes. EmpezarÃ© explorando la estructura del dataset.

Excelente, veo que tienes un dataset organizado en dos clases: SCD (enfermedad de cÃ©lulas falciformes) y Healthy (cÃ©lulas sanas). Vamos a explorar cada carpeta para entender mejor la distribuciÃ³n de datos.

Ahora veo la estructura del dataset:

**DistribuciÃ³n de datos:**
- **SCD (cÃ©lulas enfermas):** ~80 imÃ¡genes
- **Healthy (cÃ©lulas sanas):** ~96 imÃ¡genes
- **Total:** ~176 imÃ¡genes

**Observaciones iniciales:**
- ImÃ¡genes de alta resoluciÃ³n (5-7MB cada una)
- Dataset relativamente balanceado
- Nombres con timestamps sugieren capturas secuenciales

Ahora voy a examinar algunas imÃ¡genes para entender mejor las caracterÃ­sticas visuales:

Ahora tengo una comprensiÃ³n clara del dataset. Vamos a crear un plan de trabajo para desarrollar un clasificador efectivo:

## ğŸ“Š AnÃ¡lisis del Dataset de Hologramas

### **CaracterÃ­sticas del Dataset:**
- **Total de imÃ¡genes:** ~176 (80 SCD + 96 Healthy)
- **ResoluciÃ³n:** 3000Ã—4000 pÃ­xeles (muy alta resoluciÃ³n)
- **Formato:** PNG a color (3 canales)
- **TamaÃ±o por imagen:** 5-7MB
- **Balance:** Relativamente balanceado (52% healthy, 48% SCD)

### **DesafÃ­os Identificados:**
1. **Dataset pequeÃ±o** â†’ Alto riesgo de overfitting
2. **Alta resoluciÃ³n** â†’ Necesidad de optimizaciÃ³n computacional
3. **Hologramas** â†’ Requiere preprocesamiento especializado
4. **Variabilidad limitada** â†’ Necesidad de augmentation agresiva

## ğŸš€ Plan de Trabajo EstratÃ©gico

He creado un plan de 10 pasos para desarrollar un clasificador robusto:

### **Fase 1: AnÃ¡lisis y Preprocesamiento**
- AnÃ¡lisis exploratorio detallado
- Pipeline de preprocesamiento optimizado para hologramas
- Estrategias de data augmentation especÃ­ficas

### **Fase 2: Desarrollo del Modelo**
- ExtracciÃ³n de caracterÃ­sticas especÃ­ficas de hologramas
- Arquitectura CNN ligera con regularizaciÃ³n fuerte
- Transfer learning con modelos pre-entrenados

### **Fase 3: ValidaciÃ³n y OptimizaciÃ³n**
- ValidaciÃ³n cruzada estratificada
- TÃ©cnicas anti-overfitting avanzadas
- Ensemble de modelos para mayor robustez

Â¿Te gustarÃ­a que comience implementando el anÃ¡lisis exploratorio detallado? Esto nos darÃ¡ insights importantes sobre las diferencias visuales entre cÃ©lulas sanas y enfermas, y nos ayudarÃ¡ a definir las mejores estrategias de preprocesamiento y augmentation.

---

**User**

me parece

---

**Cursor**

Â¡Perfecto! Vamos a comenzar con el anÃ¡lisis exploratorio detallado. MarcarÃ© la primera tarea como en progreso y empezarÃ© la implementaciÃ³n.

```python
#!/usr/bin/env python3
"""
AnÃ¡lisis Exploratorio del Dataset de Hologramas de GlÃ³bulos SanguÃ­neos
Proyecto: ClasificaciÃ³n de cÃ©lulas sanas vs SCD
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import cv2
from pathlib import Path
import pandas as pd
from sklearn.preprocessing import StandardScaler
from skimage import feature, filters, measure
import warnings
warnings.filterwarnings('ignore')

# ConfiguraciÃ³n para grÃ¡ficos en espaÃ±ol
plt.rcParams['font.size'] = 12
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['figure.figsize'] = (15, 10)

class HologramDatasetAnalyzer:
    def __init__(self, dataset_path="dataset"):
        self.dataset_path = Path(dataset_path)
        self.classes = ["SCD", "Healthy"]
        self.class_paths = {
            "SCD": self.dataset_path / "SCD",
            "Healthy": self.dataset_path / "Healthy"
        }
        self.results = {}
        
    def load_image_info(self):
        """Cargar informaciÃ³n bÃ¡sica de todas las imÃ¡genes"""
        print("ğŸ“Š Cargando informaciÃ³n del dataset...")
        
        image_info = []
        for class_name in self.classes:
            class_path = self.class_paths[class_name]
            image_files = list(class_path.glob("*.png"))
            
            print(f"   â””â”€ {class_name}: {len(image_files)} imÃ¡genes")
            
            for img_path in image_files:
                # InformaciÃ³n bÃ¡sica del archivo
                file_size = img_path.stat().st_size / (1024*1024)  # MB
                
                # Cargar imagen para obtener dimensiones
                img = cv2.imread(str(img_path))
                if img is not None:
                    height, width, channels = img.shape
                    
                    image_info.append({
                        'clase': class_name,
                        'archivo': img_path.name,
                        'ruta': str(img_path),
                        'alto': height,
                        'ancho': width,
                        'canales': channels,
                        'tamaÃ±o_mb': file_size
                    })
        
        self.image_df = pd.DataFrame(image_info)
        return self.image_df
    
    def basic_statistics(self):
        """EstadÃ­sticas bÃ¡sicas del dataset"""
        print("\nğŸ“ˆ ESTADÃSTICAS BÃSICAS DEL DATASET")
        print("=" * 50)
        
        # Resumen por clase
        summary = self.image_df.groupby('clase').agg({
            'archivo': 'count',
            'tamaÃ±o_mb': ['mean', 'std', 'min', 'max'],
            'alto': ['mean', 'std'],
            'ancho': ['mean', 'std']
        }).round(2)
        
        print("DistribuciÃ³n por clase:")
        for clase in self.classes:
            count = len(self.image_df[self.image_df['clase'] == clase])
            percentage = (count / len(self.image_df)) * 100
            print(f"   {clase}: {count} imÃ¡genes ({percentage:.1f}%)")
        
        print(f"\nTotal de imÃ¡genes: {len(self.image_df)}")
        print(f"ResoluciÃ³n promedio: {self.image_df['alto'].mean():.0f} x {self.image_df['ancho'].mean():.0f}")
        print(f"TamaÃ±o promedio por imagen: {self.image_df['tamaÃ±o_mb'].mean():.1f} MB")
        print(f"Espacio total del dataset: {self.image_df['tamaÃ±o_mb'].sum():.1f} MB")
        
        return summary
    
    def visualize_samples(self, samples_per_class=4):
        """Visualizar muestras de cada clase"""
        print(f"\nğŸ–¼ï¸  Visualizando {samples_per_class} muestras por clase...")
        
        fig, axes = plt.subplots(2, samples_per_class, figsize=(20, 10))
        fig.suptitle('Muestras del Dataset de Hologramas', fontsize=16, fontweight='bold')
        
        for class_idx, class_name in enumerate(self.classes):
            class_images = self.image_df[self.image_df['clase'] == class_name]
            sample_images = class_images.sample(min(samples_per_class, len(class_images)))
            
            for img_idx, (_, img_info) in enumerate(sample_images.iterrows()):
                if img_idx >= samples_per_class:
                    break
                    
                # Cargar y redimensionar imagen para visualizaciÃ³n
                img = cv2.imread(img_info['ruta'])
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                
                # Redimensionar para visualizaciÃ³n
                img_resized = cv2.resize(img_rgb, (400, 300))
                
                ax = axes[class_idx, img_idx]
                ax.imshow(img_resized)
                ax.set_title(f'{class_name}\n{img_info["archivo"][:15]}...', fontsize=10)
                ax.axis('off')
        
        plt.tight_layout()
        plt.savefig('dataset_samples.png', dpi=150, bbox_inches='tight')
        plt.show()
    
    def analyze_pixel_distributions(self, sample_size=5):
        """Analizar distribuciones de pÃ­xeles"""
        print(f"\nğŸ“Š Analizando distribuciones de pÃ­xeles (muestra de {sample_size} por clase)...")
        
        pixel_data = {class_name: [] for class_name in self.classes}
        
        for class_name in self.classes:
            class_images = self.image_df[self.image_df['clase'] == class_name]
            sample_images = class_images.sample(min(sample_size, len(class_images)))
            
            for _, img_info in sample_images.iterrows():
                img = cv2.imread(img_info['ruta'])
                # Convertir a escala de grises para anÃ¡lisis mÃ¡s simple
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                
                # Redimensionar para acelerar anÃ¡lisis
                gray_resized = cv2.resize(gray, (500, 375))
                pixel_data[class_name].extend(gray_resized.flatten())
        
        # Crear histogramas
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('AnÃ¡lisis de DistribuciÃ³n de PÃ­xeles', fontsize=16, fontweight='bold')
        
        # Histogramas por clase
        for idx, class_name in enumerate(self.classes):
            ax = axes[0, idx]
            ax.hist(pixel_data[class_name], bins=50, alpha=0.7, 
                   color='red' if class_name == 'SCD' else 'blue', density=True)
            ax.set_title(f'Histograma - {class_name}')
            ax.set_xlabel('Intensidad de PÃ­xel')
            ax.set_ylabel('Densidad')
            ax.grid(True, alpha=0.3)
        
        # ComparaciÃ³n directa
        ax = axes[1, 0]
        for class_name in self.classes:
            color = 'red' if class_name == 'SCD' else 'blue'
            ax.hist(pixel_data[class_name], bins=50, alpha=0.6, 
                   label=class_name, color=color, density=True)
        ax.set_title('ComparaciÃ³n de Distribuciones')
        ax.set_xlabel('Intensidad de PÃ­xel')
        ax.set_ylabel('Densidad')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # EstadÃ­sticas
        ax = axes[1, 1]
        stats_data = []
        for class_name in self.classes:
            data = np.array(pixel_data[class_name])
            stats_data.append([
                class_name,
                np.mean(data),
                np.std(data),
                np.median(data),
                np.percentile(data, 25),
                np.percentile(data, 75)
            ])
        
        stats_df = pd.DataFrame(stats_data, columns=['Clase', 'Media', 'Std', 'Mediana', 'Q25', 'Q75'])
        ax.axis('tight')
        ax.axis('off')
        table = ax.table(cellText=stats_df.round(2).values,
                        colLabels=stats_df.columns,
                        cellLoc='center',
                        loc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        ax.set_title('EstadÃ­sticas por Clase')
        
        plt.tight_layout()
        plt.savefig('pixel_distribution_analysis.png', dpi=150, bbox_inches='tight')
        plt.show()
        
        return pixel_data, stats_df
    
    def analyze_textures(self, sample_size=3):
        """AnÃ¡lisis de texturas usando Local Binary Patterns"""
        print(f"\nğŸ” Analizando texturas (muestra de {sample_size} por clase)...")
        
        texture_features = {class_name: [] for class_name in self.classes}
        
        fig, axes = plt.subplots(2, sample_size, figsize=(15, 8))
        fig.suptitle('AnÃ¡lisis de Texturas - Local Binary Patterns', fontsize=16, fontweight='bold')
        
        for class_idx, class_name in enumerate(self.classes):
            class_images = self.image_df[self.image_df['clase'] == class_name]
            sample_images = class_images.sample(min(sample_size, len(class_images)))
            
            for img_idx, (_, img_info) in enumerate(sample_images.iterrows()):
                if img_idx >= sample_size:
                    break
                
                # Cargar imagen
                img = cv2.imread(img_info['ruta'])
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                
                # Redimensionar para anÃ¡lisis
                gray_resized = cv2.resize(gray, (500, 375))
                
                # Calcular Local Binary Pattern
                lbp = feature.local_binary_pattern(gray_resized, P=8, R=1, method='uniform')
                
                # Visualizar
                ax = axes[class_idx, img_idx]
                ax.imshow(lbp, cmap='gray')
                ax.set_title(f'{class_name} - LBP\n{img_info["archivo"][:10]}...')
                ax.axis('off')
                
                # Guardar caracterÃ­sticas de textura
                lbp_hist, _ = np.histogram(lbp.ravel(), bins=10)
                texture_features[class_name].append(lbp_hist)
        
        plt.tight_layout()
        plt.savefig('texture_analysis.png', dpi=150, bbox_inches='tight')
        plt.show()
        
        return texture_features
    
    def hologram_specific_analysis(self, sample_size=2):
        """AnÃ¡lisis especÃ­fico para hologramas: patrones de interferencia"""
        print(f"\nğŸŒŠ AnÃ¡lisis especÃ­fico de hologramas (muestra de {sample_size} por clase)...")
        
        fig, axes = plt.subplots(2, sample_size * 3, figsize=(18, 8))
        fig.suptitle('AnÃ¡lisis EspecÃ­fico de Hologramas', fontsize=16, fontweight='bold')
        
        for class_idx, class_name in enumerate(self.classes):
            class_images = self.image_df[self.image_df['clase'] == class_name]
            sample_images = class_images.sample(min(sample_size, len(class_images)))
            
            for img_idx, (_, img_info) in enumerate(sample_images.iterrows()):
                if img_idx >= sample_size:
                    break
                
                # Cargar imagen
                img = cv2.imread(img_info['ruta'])
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                gray_resized = cv2.resize(gray, (400, 300))
                
                base_col = img_idx * 3
                
                # Imagen original
                axes[class_idx, base_col].imshow(gray_resized, cmap='gray')
                axes[class_idx, base_col].set_title(f'{class_name} - Original')
                axes[class_idx, base_col].axis('off')
                
                # Filtro de frecuencias (FFT)
                fft = np.fft.fft2(gray_resized)
                fft_shift = np.fft.fftshift(fft)
                magnitude_spectrum = np.log(np.abs(fft_shift) + 1)
                
                axes[class_idx, base_col + 1].imshow(magnitude_spectrum, cmap='hot')
                axes[class_idx, base_col + 1].set_title(f'{class_name} - FFT')
                axes[class_idx, base_col + 1].axis('off')
                
                # DetecciÃ³n de bordes (Canny)
                edges = cv2.Canny(gray_resized, 50, 150)
                
                axes[class_idx, base_col + 2].imshow(edges, cmap='gray')
                axes[class_idx, base_col + 2].set_title(f'{class_name} - Bordes')
                axes[class_idx, base_col + 2].axis('off')
        
        plt.tight_layout()
        plt.savefig('hologram_specific_analysis.png', dpi=150, bbox_inches='tight')
        plt.show()
    
    def generate_report(self):
        """Generar reporte completo del anÃ¡lisis"""
        print("\nğŸ“‹ REPORTE COMPLETO DEL ANÃLISIS")
        print("=" * 60)
        
        total_images = len(self.image_df)
        scd_count = len(self.image_df[self.image_df['clase'] == 'SCD'])
        healthy_count = len(self.image_df[self.image_df['clase'] == 'Healthy'])
        
        report = f"""
RESUMEN EJECUTIVO DEL DATASET
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š COMPOSICIÃ“N DEL DATASET:
   â€¢ Total de imÃ¡genes: {total_images}
   â€¢ CÃ©lulas SCD (enfermas): {scd_count} ({scd_count/total_images*100:.1f}%)
   â€¢ CÃ©lulas Healthy (sanas): {healthy_count} ({healthy_count/total_images*100:.1f}%)
   â€¢ Balance del dataset: {'âœ… Balanceado' if abs(scd_count - healthy_count) < 20 else 'âš ï¸ Desbalanceado'}

ğŸ–¼ï¸ CARACTERÃSTICAS TÃ‰CNICAS:
   â€¢ ResoluciÃ³n: {self.image_df['alto'].iloc[0]} x {self.image_df['ancho'].iloc[0]} pÃ­xeles
   â€¢ Formato: PNG a color (3 canales)
   â€¢ TamaÃ±o promedio: {self.image_df['tamaÃ±o_mb'].mean():.1f} MB por imagen
   â€¢ Espacio total: {self.image_df['tamaÃ±o_mb'].sum():.1f} MB

ğŸ” DESAFÃOS IDENTIFICADOS:
   â€¢ Dataset pequeÃ±o ({total_images} imÃ¡genes) â†’ Alto riesgo de overfitting
   â€¢ Alta resoluciÃ³n â†’ Necesidad de optimizaciÃ³n computacional
   â€¢ ImÃ¡genes hologrÃ¡ficas â†’ Requiere preprocesamiento especializado

ğŸ’¡ RECOMENDACIONES PARA EL CLASIFICADOR:
   1. Data Augmentation agresiva (rotaciones, flips, variaciones de contraste)
   2. Transfer Learning con modelos pre-entrenados
   3. ValidaciÃ³n cruzada estratificada
   4. RegularizaciÃ³n fuerte (dropout, batch normalization)
   5. Early stopping para prevenir overfitting
   6. Ensemble de modelos para mayor robustez

ğŸš€ PRÃ“XIMOS PASOS:
   1. Implementar pipeline de preprocesamiento
   2. Desarrollar estrategias de data augmentation
   3. Extraer caracterÃ­sticas especÃ­ficas de hologramas
   4. DiseÃ±ar arquitectura CNN optimizada
        """
        
        print(report)
        
        # Guardar reporte
        with open('dataset_analysis_report.txt', 'w', encoding='utf-8') as f:
            f.write(report)
        
        return report

def main():
    """FunciÃ³n principal para ejecutar todo el anÃ¡lisis"""
    print("ğŸ”¬ ANÃLISIS EXPLORATORIO DEL DATASET DE HOLOGRAMAS")
    print("=" * 60)
    
    # Inicializar analizador
    analyzer = HologramDatasetAnalyzer()
    
    # Ejecutar anÃ¡lisis completo
    analyzer.load_image_info()
    analyzer.basic_statistics()
    analyzer.visualize_samples()
    analyzer.analyze_pixel_distributions()
    analyzer.analyze_textures()
    analyzer.hologram_specific_analysis()
    analyzer.generate_report()
    
    print("\nâœ… AnÃ¡lisis completo terminado!")
    print("ğŸ“ Archivos generados:")
    print("   â€¢ dataset_samples.png")
    print("   â€¢ pixel_distribution_analysis.png")
    print("   â€¢ texture_analysis.png")
    print("   â€¢ hologram_specific_analysis.png")
    print("   â€¢ dataset_analysis_report.txt")

if __name__ == "__main__":
    main()
```

Veo que necesitamos instalar las dependencias. Voy a crear un archivo `requirements.txt` y luego instalar las librerÃ­as necesarias:

```pip-requirements
numpy>=1.21.0
matplotlib>=3.5.0
seaborn>=0.11.0
pandas>=1.3.0
scikit-learn>=1.0.0
scikit-image>=0.19.0
opencv-python>=4.5.0
Pillow>=8.3.0
tensorflow>=2.8.0
torch>=1.11.0
torchvision>=0.12.0
jupyter>=1.0.0
ipykernel>=6.0.0
```

Â¡Excelente! Las dependencias se instalaron correctamente. Ahora ejecutemos el anÃ¡lisis exploratorio:

Â¡Excelente! El anÃ¡lisis exploratorio se completÃ³ exitosamente. Veamos los resultados detallados:

## ğŸ¯ **ANÃLISIS EXPLORATORIO COMPLETADO**

Â¡Excelente! He terminado el anÃ¡lisis exploratorio detallado del dataset. AquÃ­ estÃ¡n los **hallazgos clave**:

### ğŸ“Š **Resultados del AnÃ¡lisis:**

**ComposiciÃ³n del Dataset:**
- **Total:** 196 imÃ¡genes (mÃ¡s de las estimadas inicialmente)
- **SCD (enfermas):** 83 imÃ¡genes (42.3%)
- **Healthy (sanas):** 113 imÃ¡genes (57.7%)
- **Balance:** Ligeramente desbalanceado pero manejable

**CaracterÃ­sticas TÃ©cnicas:**
- **ResoluciÃ³n:** 3000Ã—4000 pÃ­xeles (Â¡12 megapÃ­xeles!)
- **TamaÃ±o promedio:** 6.4 MB por imagen
- **Espacio total:** 1.25 GB
- **Calidad:** ImÃ¡genes hologrÃ¡ficas de muy alta resoluciÃ³n

### ğŸ” **Archivos Generados:**
âœ… `dataset_samples.png` - Muestras visuales de ambas clases
âœ… `pixel_distribution_analysis.png` - AnÃ¡lisis estadÃ­stico de pÃ­xeles
âœ… `texture_analysis.png` - Patrones de textura (LBP)
âœ… `hologram_specific_analysis.png` - AnÃ¡lisis FFT y detecciÃ³n de bordes
âœ… `dataset_analysis_report.txt` - Reporte ejecutivo completo

### ğŸš¨ **DesafÃ­os Confirmados:**
1. **Dataset pequeÃ±o** (196 imÃ¡genes) â†’ Riesgo alto de overfitting
2. **Alta resoluciÃ³n** â†’ Necesidad de optimizaciÃ³n computacional
3. **Ligero desbalance** â†’ RequerirÃ¡ estratificaciÃ³n cuidadosa
4. **Naturaleza hologrÃ¡fica** â†’ Preprocesamiento especializado

### ğŸš€ **PrÃ³ximo Paso Recomendado:**
BasÃ¡ndome en estos resultados, sugiero proceder con el **pipeline de preprocesamiento** que serÃ¡ crucial para manejar la alta resoluciÃ³n y optimizar las imÃ¡genes hologrÃ¡ficas.

Â¿Te gustarÃ­a que implemente el pipeline de preprocesamiento ahora? Esto incluirÃ¡:
- Redimensionado inteligente
- NormalizaciÃ³n especÃ­fica para hologramas
- Filtros de realce de contraste
- PreparaciÃ³n para data augmentation

---

**User**

puedes continuar

---

**Cursor**

Â¡Perfecto! Continuemos con el pipeline de preprocesamiento. MarcarÃ© la siguiente tarea como en progreso y la implementarÃ©.

```python
#!/usr/bin/env python3
"""
Pipeline de Preprocesamiento para Hologramas de GlÃ³bulos SanguÃ­neos
Proyecto: ClasificaciÃ³n de cÃ©lulas sanas vs SCD

Este mÃ³dulo implementa tÃ©cnicas especializadas para el preprocesamiento
de imÃ¡genes hologrÃ¡ficas con el objetivo de mejorar la calidad y 
facilitar el entrenamiento del clasificador.
"""

import numpy as np
import cv2
import os
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import json
from typing import Tuple, List, Dict, Optional
import warnings
warnings.filterwarnings('ignore')

class HologramPreprocessor:
    """
    Clase para el preprocesamiento especializado de hologramas
    """
    
    def __init__(self, target_size: Tuple[int, int] = (512, 512)):
        """
        Inicializar el preprocesador
        
        Args:
            target_size: TamaÃ±o objetivo para redimensionar las imÃ¡genes
        """
        self.target_size = target_size
        self.label_encoder = LabelEncoder()
        self.preprocessing_stats = {}
        
    def load_and_preprocess_image(self, image_path: str, apply_hologram_enhancement: bool = True) -> np.ndarray:
        """
        Cargar y preprocesar una sola imagen
        
        Args:
            image_path: Ruta de la imagen
            apply_hologram_enhancement: Si aplicar mejoras especÃ­ficas para hologramas
            
        Returns:
            Imagen preprocesada como array numpy
        """
        # Cargar imagen
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"No se pudo cargar la imagen: {image_path}")
            
        # Convertir a RGB
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # Aplicar pipeline de preprocesamiento
        processed_img = self._preprocess_pipeline(img_rgb, apply_hologram_enhancement)
        
        return processed_img
    
    def _preprocess_pipeline(self, img: np.ndarray, apply_hologram_enhancement: bool = True) -> np.ndarray:
        """
        Pipeline completo de preprocesamiento
        
        Args:
            img: Imagen original
            apply_hologram_enhancement: Si aplicar mejoras especÃ­ficas para hologramas
            
        Returns:
            Imagen preprocesada
        """
        # 1. Redimensionado inteligente
        img_resized = self._smart_resize(img)
        
        # 2. Mejoras especÃ­ficas para hologramas
        if apply_hologram_enhancement:
            img_enhanced = self._hologram_enhancement(img_resized)
        else:
            img_enhanced = img_resized
            
        # 3. NormalizaciÃ³n
        img_normalized = self._normalize_image(img_enhanced)
        
        # 4. Mejora de contraste adaptativo
        img_contrast = self._adaptive_contrast_enhancement(img_normalized)
        
        return img_contrast
    
    def _smart_resize(self, img: np.ndarray) -> np.ndarray:
        """
        Redimensionado inteligente que preserva aspectos importantes
        
        Args:
            img: Imagen original
            
        Returns:
            Imagen redimensionada
        """
        h, w = img.shape[:2]
        target_h, target_w = self.target_size
        
        # Calcular ratio de aspecto
        aspect_ratio = w / h
        target_aspect_ratio = target_w / target_h
        
        if aspect_ratio > target_aspect_ratio:
            # Imagen mÃ¡s ancha, ajustar por ancho
            new_w = target_w
            new_h = int(target_w / aspect_ratio)
        else:
            # Imagen mÃ¡s alta, ajustar por alto
            new_h = target_h
            new_w = int(target_h * aspect_ratio)
        
        # Redimensionar manteniendo proporciones
        img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
        
        # Rellenar para llegar al tamaÃ±o objetivo (padding)
        if new_h < target_h or new_w < target_w:
            # Crear imagen con padding
            padded_img = np.zeros((target_h, target_w, img.shape[2]), dtype=img.dtype)
            
            # Calcular posiciÃ³n para centrar
            start_y = (target_h - new_h) // 2
            start_x = (target_w - new_w) // 2
            
            # Colocar imagen redimensionada en el centro
            padded_img[start_y:start_y+new_h, start_x:start_x+new_w] = img_resized
            img_resized = padded_img
        
        return img_resized
    
    def _hologram_enhancement(self, img: np.ndarray) -> np.ndarray:
        """
        Mejoras especÃ­ficas para imÃ¡genes hologrÃ¡ficas
        
        Args:
            img: Imagen de entrada
            
        Returns:
            Imagen con mejoras hologrÃ¡ficas
        """
        # Convertir a escala de grises para anÃ¡lisis
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) if len(img.shape) == 3 else img
        
        # 1. Filtro de realce de patrones de interferencia
        # Usar filtro gaussiano inverso para realzar detalles finos
        gaussian = cv2.GaussianBlur(gray, (0, 0), 2.0)
        enhanced = cv2.addWeighted(gray, 2.0, gaussian, -1.0, 0)
        enhanced = np.clip(enhanced, 0, 255).astype(np.uint8)
        
        # 2. Filtro de frecuencia para realzar patrones hologrÃ¡ficos
        # Aplicar FFT para trabajar en dominio de frecuencia
        f_transform = np.fft.fft2(enhanced)
        f_shift = np.fft.fftshift(f_transform)
        
        # Crear mÃ¡scara de paso alto para realzar detalles
        rows, cols = enhanced.shape
        crow, ccol = rows // 2, cols // 2
        mask = np.ones((rows, cols), np.uint8)
        r = 30  # Radio del filtro
        mask[crow-r:crow+r, ccol-r:ccol+r] = 0
        
        # Aplicar mÃ¡scara y transformada inversa
        f_shift_masked = f_shift * mask
        f_ishift = np.fft.ifftshift(f_shift_masked)
        img_back = np.fft.ifft2(f_ishift)
        img_back = np.real(img_back)
        
        # Normalizar resultado
        img_back = ((img_back - img_back.min()) / (img_back.max() - img_back.min()) * 255).astype(np.uint8)
        
        # 3. Combinar imagen original con mejoras
        # Usar imagen mejorada como canal de intensidad
        if len(img.shape) == 3:
            # Mantener informaciÃ³n de color pero mejorar detalles
            hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
            hsv[:, :, 2] = cv2.addWeighted(hsv[:, :, 2], 0.7, img_back, 0.3, 0)
            enhanced_color = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)
            return enhanced_color
        else:
            return img_back
    
    def _normalize_image(self, img: np.ndarray) -> np.ndarray:
        """
        NormalizaciÃ³n especÃ­fica para hologramas
        
        Args:
            img: Imagen a normalizar
            
        Returns:
            Imagen normalizada
        """
        if img.dtype != np.float32:
            img = img.astype(np.float32)
        
        # NormalizaciÃ³n por canal
        if len(img.shape) == 3:
            # Para imÃ¡genes a color, normalizar cada canal independientemente
            normalized = np.zeros_like(img)
            for i in range(img.shape[2]):
                channel = img[:, :, i]
                # NormalizaciÃ³n robusta usando percentiles para evitar outliers
                p2, p98 = np.percentile(channel, (2, 98))
                normalized[:, :, i] = np.clip((channel - p2) / (p98 - p2), 0, 1)
        else:
            # Para escala de grises
            p2, p98 = np.percentile(img, (2, 98))
            normalized = np.clip((img - p2) / (p98 - p2), 0, 1)
        
        return normalized
    
    def _adaptive_contrast_enhancement(self, img: np.ndarray) -> np.ndarray:
        """
        Mejora de contraste adaptativo
        
        Args:
            img: Imagen normalizada
            
        Returns:
            Imagen con contraste mejorado
        """
        # Convertir a uint8 para CLAHE
        if img.dtype == np.float32:
            img_uint8 = (img * 255).astype(np.uint8)
        else:
            img_uint8 = img
        
        if len(img.shape) == 3:
            # Para imÃ¡genes a color, aplicar CLAHE en espacio LAB
            lab = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2LAB)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            lab[:, :, 0] = clahe.apply(lab[:, :, 0])
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        else:
            # Para escala de grises
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            enhanced = clahe.apply(img_uint8)
        
        # Convertir de vuelta a float32 normalizado
        return enhanced.astype(np.float32) / 255.0
    
    def load_dataset(self, dataset_path: str = "dataset", test_size: float = 0.2, 
                    random_state: int = 42, apply_hologram_enhancement: bool = True) -> Dict:
        """
        Cargar y preprocesar todo el dataset
        
        Args:
            dataset_path: Ruta del dataset
            test_size: ProporciÃ³n del conjunto de prueba
            random_state: Semilla para reproducibilidad
            apply_hologram_enhancement: Si aplicar mejoras hologrÃ¡ficas
            
        Returns:
            Diccionario con datos preprocesados
        """
        print("ğŸ”„ Cargando y preprocesando dataset...")
        
        # Cargar rutas de archivos y etiquetas
        image_paths = []
        labels = []
        
        dataset_path = Path(dataset_path)
        classes = ["SCD", "Healthy"]
        
        for class_name in classes:
            class_path = dataset_path / class_name
            if class_path.exists():
                image_files = list(class_path.glob("*.png"))
                print(f"   â””â”€ {class_name}: {len(image_files)} imÃ¡genes")
                
                for img_path in image_files:
                    image_paths.append(str(img_path))
                    labels.append(class_name)
        
        # Codificar etiquetas
        labels_encoded = self.label_encoder.fit_transform(labels)
        
        # DivisiÃ³n estratificada
        X_train_paths, X_test_paths, y_train, y_test = train_test_split(
            image_paths, labels_encoded, test_size=test_size, 
            random_state=random_state, stratify=labels_encoded
        )
        
        print(f"\nğŸ“Š DivisiÃ³n del dataset:")
        print(f"   â€¢ Entrenamiento: {len(X_train_paths)} imÃ¡genes")
        print(f"   â€¢ Prueba: {len(X_test_paths)} imÃ¡genes")
        
        # Preprocesar imÃ¡genes
        print("\nğŸ”„ Preprocesando imÃ¡genes...")
        
        X_train = []
        X_test = []
        
        # Procesar conjunto de entrenamiento
        print("   â””â”€ Procesando conjunto de entrenamiento...")
        for i, path in enumerate(X_train_paths):
            if i % 20 == 0:
                print(f"      Progreso: {i+1}/{len(X_train_paths)}")
            processed_img = self.load_and_preprocess_image(path, apply_hologram_enhancement)
            X_train.append(processed_img)
        
        # Procesar conjunto de prueba
        print("   â””â”€ Procesando conjunto de prueba...")
        for i, path in enumerate(X_test_paths):
            if i % 10 == 0:
                print(f"      Progreso: {i+1}/{len(X_test_paths)}")
            processed_img = self.load_and_preprocess_image(path, apply_hologram_enhancement)
            X_test.append(processed_img)
        
        # Convertir a arrays numpy
        X_train = np.array(X_train)
        X_test = np.array(X_test)
        y_train = np.array(y_train)
        y_test = np.array(y_test)
        
        # Guardar estadÃ­sticas de preprocesamiento
        self.preprocessing_stats = {
            'target_size': self.target_size,
            'n_train': len(X_train),
            'n_test': len(X_test),
            'n_classes': len(self.label_encoder.classes_),
            'classes': self.label_encoder.classes_.tolist(),
            'train_distribution': {
                class_name: int(np.sum(y_train == i)) 
                for i, class_name in enumerate(self.label_encoder.classes_)
            },
            'test_distribution': {
                class_name: int(np.sum(y_test == i)) 
                for i, class_name in enumerate(self.label_encoder.classes_)
            },
            'hologram_enhancement': apply_hologram_enhancement
        }
        
        print(f"\nâœ… Preprocesamiento completado!")
        print(f"   â€¢ Forma X_train: {X_train.shape}")
        print(f"   â€¢ Forma X_test: {X_test.shape}")
        print(f"   â€¢ Forma y_train: {y_train.shape}")
        print(f"   â€¢ Forma y_test: {y_test.shape}")
        
        return {
            'X_train': X_train,
            'X_test': X_test,
            'y_train': y_train,
            'y_test': y_test,
            'train_paths': X_train_paths,
            'test_paths': X_test_paths,
            'label_encoder': self.label_encoder,
            'preprocessing_stats': self.preprocessing_stats
        }
    
    def visualize_preprocessing_effects(self, original_img_path: str, save_path: str = "preprocessing_comparison.png"):
        """
        Visualizar los efectos del preprocesamiento
        
        Args:
            original_img_path: Ruta de una imagen original
            save_path: Ruta donde guardar la comparaciÃ³n
        """
        print("ğŸ–¼ï¸ Generando visualizaciÃ³n de efectos de preprocesamiento...")
        
        # Cargar imagen original
        original_img = cv2.imread(original_img_path)
        original_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
        
        # Aplicar diferentes etapas del preprocesamiento
        step1_resized = self._smart_resize(original_rgb)
        step2_enhanced = self._hologram_enhancement(step1_resized)
        step3_normalized = self._normalize_image(step2_enhanced)
        step4_contrast = self._adaptive_contrast_enhancement(step3_normalized)
        
        # Crear visualizaciÃ³n
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Efectos del Pipeline de Preprocesamiento', fontsize=16, fontweight='bold')
        
        # Imagen original (redimensionada para visualizaciÃ³n)
        original_display = cv2.resize(original_rgb, (400, 300))
        axes[0, 0].imshow(original_display)
        axes[0, 0].set_title('Original\n(Redimensionada para display)')
        axes[0, 0].axis('off')
        
        # Redimensionado inteligente
        axes[0, 1].imshow(step1_resized)
        axes[0, 1].set_title(f'Redimensionado Inteligente\n{step1_resized.shape[:2]}')
        axes[0, 1].axis('off')
        
        # Mejoras hologrÃ¡ficas
        axes[0, 2].imshow(step2_enhanced)
        axes[0, 2].set_title('Mejoras HologrÃ¡ficas\n(Realce de patrones)')
        axes[0, 2].axis('off')
        
        # NormalizaciÃ³n
        axes[1, 0].imshow(step3_normalized)
        axes[1, 0].set_title('NormalizaciÃ³n\n(Percentiles 2-98)')
        axes[1, 0].axis('off')
        
        # Mejora de contraste
        axes[1, 1].imshow(step4_contrast)
        axes[1, 1].set_title('Contraste Adaptativo\n(CLAHE)')
        axes[1, 1].axis('off')
        
        # Histograma de comparaciÃ³n
        axes[1, 2].hist(original_rgb.flatten(), bins=50, alpha=0.7, label='Original', color='red', density=True)
        axes[1, 2].hist((step4_contrast * 255).astype(np.uint8).flatten(), bins=50, alpha=0.7, label='Procesada', color='blue', density=True)
        axes[1, 2].set_title('ComparaciÃ³n de Histogramas')
        axes[1, 2].set_xlabel('Intensidad de PÃ­xel')
        axes[1, 2].set_ylabel('Densidad')
        axes[1, 2].legend()
        axes[1, 2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… VisualizaciÃ³n guardada en: {save_path}")
    
    def save_preprocessing_config(self, filepath: str = "preprocessing_config.json"):
        """
        Guardar configuraciÃ³n de preprocesamiento
        
        Args:
            filepath: Ruta donde guardar la configuraciÃ³n
        """
        config = {
            'target_size': self.target_size,
            'preprocessing_stats': self.preprocessing_stats
        }
        
        with open(filepath, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"ğŸ’¾ ConfiguraciÃ³n guardada en: {filepath}")

def main():
    """
    FunciÃ³n principal para demostrar el pipeline de preprocesamiento
    """
    print("ğŸ”¬ PIPELINE DE PREPROCESAMIENTO PARA HOLOGRAMAS")
    print("=" * 60)
    
    # Inicializar preprocesador
    preprocessor = HologramPreprocessor(target_size=(512, 512))
    
    # Cargar y preprocesar dataset completo
    dataset = preprocessor.load_dataset(
        dataset_path="dataset",
        test_size=0.2,
        random_state=42,
        apply_hologram_enhancement=True
    )
    
    # Mostrar estadÃ­sticas
    print("\nğŸ“Š ESTADÃSTICAS DEL DATASET PREPROCESADO:")
    print("=" * 50)
    stats = dataset['preprocessing_stats']
    print(f"TamaÃ±o objetivo: {stats['target_size']}")
    print(f"Total de clases: {stats['n_classes']}")
    print(f"Clases: {', '.join(stats['classes'])}")
    print(f"\nDistribuciÃ³n de entrenamiento:")
    for class_name, count in stats['train_distribution'].items():
        print(f"   {class_name}: {count} imÃ¡genes")
    print(f"\nDistribuciÃ³n de prueba:")
    for class_name, count in stats['test_distribution'].items():
        print(f"   {class_name}: {count} imÃ¡genes")
    
    # Generar visualizaciÃ³n de una imagen de ejemplo
    sample_paths = dataset['train_paths'][:2]  # Tomar dos ejemplos
    for i, path in enumerate(sample_paths):
        save_path = f"preprocessing_example_{i+1}.png"
        preprocessor.visualize_preprocessing_effects(path, save_path)
    
    # Guardar configuraciÃ³n
    preprocessor.save_preprocessing_config()
    
    # Guardar dataset preprocesado
    print("\nğŸ’¾ Guardando dataset preprocesado...")
    np.savez_compressed(
        'preprocessed_dataset.npz',
        X_train=dataset['X_train'],
        X_test=dataset['X_test'],
        y_train=dataset['y_train'],
        y_test=dataset['y_test']
    )
    
    print("âœ… Pipeline de preprocesamiento completado!")
    print("ğŸ“ Archivos generados:")
    print("   â€¢ preprocessing_example_1.png")
    print("   â€¢ preprocessing_example_2.png") 
    print("   â€¢ preprocessing_config.json")
    print("   â€¢ preprocessed_dataset.npz")

if __name__ == "__main__":
    main()
```

Voy a corregir los errores de tipos en el cÃ³digo:

```python
        # Cargar rutas de archivos y etiquetas
        image_paths = []
        labels = []
        
        dataset_path = Path(dataset_path)
        classes = ["SCD", "Healthy"]
        
        for class_name in classes:
            class_path = dataset_path / class_name

->

        # Cargar rutas de archivos y etiquetas
        image_paths = []
        labels = []
        
        dataset_path_obj = Path(dataset_path)
        classes = ["SCD", "Healthy"]
        
        for class_name in classes:
            class_path = dataset_path_obj / class_name
```

Perfecto, los errores de tipos especÃ­ficos fueron corregidos. Los errores de importaciÃ³n restantes no son problemÃ¡ticos ya que las librerÃ­as estÃ¡n instaladas. Ahora ejecutemos el pipeline de preprocesamiento:

Â¡Excelente! El pipeline de preprocesamiento se completÃ³ exitosamente. Vamos a marcar la tarea como completada y verificar los resultados:

## ğŸ¯ **PIPELINE DE PREPROCESAMIENTO COMPLETADO**

Â¡Excelente trabajo! El pipeline de preprocesamiento se ejecutÃ³ perfectamente. AquÃ­ estÃ¡n los **resultados clave**:

### ğŸ“Š **TransformaciÃ³n del Dataset:**

**Antes del Preprocesamiento:**
- 1.25 GB de espacio
- 196 imÃ¡genes de 3000Ã—4000 pÃ­xeles
- Sin optimizaciones

**DespuÃ©s del Preprocesamiento:**
- 69 MB de espacio (**95% de reducciÃ³n!**)
- 196 imÃ¡genes de 512Ã—512 pÃ­xeles
- Optimizadas para hologramas

### ğŸ”§ **TÃ©cnicas Aplicadas:**

1. **Redimensionado Inteligente:** Preserva proporciones con padding
2. **Mejoras HologrÃ¡ficas:** Filtros FFT + realce de patrones de interferencia
3. **NormalizaciÃ³n Robusta:** Usando percentiles 2-98 para evitar outliers
4. **Contraste Adaptativo:** CLAHE en espacio LAB para mejor distribuciÃ³n

### ğŸ“ˆ **DivisiÃ³n Estratificada:**
- **Entrenamiento:** 156 imÃ¡genes (Healthy: 90, SCD: 66)
- **Prueba:** 40 imÃ¡genes (Healthy: 23, SCD: 17)
- **Balance mantenido:** ~58% Healthy, ~42% SCD

### ğŸ“ **Archivos Generados:**
âœ… `preprocessed_dataset.npz` - Dataset optimizado (69MB)
âœ… `preprocessing_example_1.png` - VisualizaciÃ³n de efectos
âœ… `preprocessing_example_2.png` - ComparaciÃ³n paso a paso
âœ… `preprocessing_config.json` - ConfiguraciÃ³n y estadÃ­sticas

### ğŸš€ **PrÃ³ximo Paso CrÃ­tico:**
Con solo **156 imÃ¡genes de entrenamiento**, necesitamos implementar **Data Augmentation agresiva** para generar variaciones sintÃ©ticas y prevenir overfitting.

Â¿Quieres que continÃºe implementando las estrategias de Data Augmentation? Esto incluirÃ¡:
- Rotaciones y flips especÃ­ficos para hologramas
- Variaciones de contraste y brillo
- Transformaciones elÃ¡sticas
- Filtros de ruido y blur
- TÃ©cnicas avanzadas como Mixup y CutMix

---

**User**

continua

---

**Cursor**

Â¡Perfecto! Continuemos con las estrategias de Data Augmentation. MarcarÃ© la tarea correspondiente como en progreso e implementarÃ© tÃ©cnicas especializadas para hologramas.

```python
#!/usr/bin/env python3
"""
Data Augmentation Especializado para Hologramas de GlÃ³bulos SanguÃ­neos
Proyecto: ClasificaciÃ³n de cÃ©lulas sanas vs SCD

Este mÃ³dulo implementa tÃ©cnicas avanzadas de data augmentation especÃ­ficamente
diseÃ±adas para hologramas, maximizando la variabilidad del dataset sin perder
caracterÃ­sticas importantes para la clasificaciÃ³n.
"""

import numpy as np
import cv2
import random
from typing import Tuple, List, Dict, Callable, Union
import matplotlib.pyplot as plt
from scipy import ndimage
from skimage import transform, filters, exposure
import albumentations as A
from albumentations.pytorch import ToTensorV2
import warnings
warnings.filterwarnings('ignore')

class HologramAugmentator:
    """
    Clase para data augmentation especializado en hologramas
    """
    
    def __init__(self, 
                 augmentation_factor: int = 8,
                 preserve_hologram_features: bool = True,
                 apply_advanced_techniques: bool = True):
        """
        Inicializar el augmentador
        
        Args:
            augmentation_factor: Factor de multiplicaciÃ³n del dataset
            preserve_hologram_features: Si preservar caracterÃ­sticas hologrÃ¡ficas
            apply_advanced_techniques: Si aplicar tÃ©cnicas avanzadas (Mixup, CutMix)
        """
        self.augmentation_factor = augmentation_factor
        self.preserve_hologram_features = preserve_hologram_features
        self.apply_advanced_techniques = apply_advanced_techniques
        self.augmentation_stats = {}
        
        # Configurar pipelines de augmentation
        self.setup_augmentation_pipelines()
    
    def setup_augmentation_pipelines(self):
        """Configurar diferentes pipelines de augmentation"""
        
        # Pipeline bÃ¡sico - transformaciones geomÃ©tricas
        self.basic_augmentations = A.Compose([
            A.RandomRotate90(p=0.5),
            A.Flip(p=0.5),
            A.ShiftScaleRotate(
                shift_limit=0.1, 
                scale_limit=0.1, 
                rotate_limit=15, 
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.8
            ),
            A.ElasticTransform(
                alpha=50, 
                sigma=5, 
                alpha_affine=5,
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.3
            )
        ])
        
        # Pipeline de mejoras visuales - preserva patrones hologrÃ¡ficos
        self.visual_augmentations = A.Compose([
            A.RandomBrightnessContrast(
                brightness_limit=0.15, 
                contrast_limit=0.15, 
                p=0.7
            ),
            A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),
            A.RandomGamma(gamma_limit=(80, 120), p=0.4),
            A.GaussNoise(var_limit=(10, 30), p=0.3),
            A.Blur(blur_limit=3, p=0.2)
        ])
        
        # Pipeline avanzado - tÃ©cnicas especÃ­ficas para hologramas
        self.hologram_augmentations = A.Compose([
            A.OpticalDistortion(
                distort_limit=0.1, 
                shift_limit=0.05,
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.3
            ),
            A.GridDistortion(
                num_steps=5, 
                distort_limit=0.1,
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.3
            ),
            A.GaussianBlur(blur_limit=(1, 3), p=0.2),
            A.MotionBlur(blur_limit=3, p=0.2)
        ])
        
        # Pipeline combinado
        self.combined_pipeline = A.Compose([
            A.OneOf([
                self.basic_augmentations,
                self.visual_augmentations,
                self.hologram_augmentations
            ], p=1.0),
            A.OneOf([
                A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),
                A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1),
                A.NoOp()
            ], p=0.5)
        ])
    
    def frequency_domain_augmentation(self, image: np.ndarray, intensity: float = 0.1) -> np.ndarray:
        """
        Augmentation en el dominio de frecuencia especÃ­fico para hologramas
        
        Args:
            image: Imagen de entrada
            intensity: Intensidad de la transformaciÃ³n
            
        Returns:
            Imagen transformada
        """
        if len(image.shape) == 3:
            # Para imÃ¡genes a color, trabajar con canal de luminancia
            gray = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
        else:
            gray = (image * 255).astype(np.uint8)
        
        # Aplicar FFT
        f_transform = np.fft.fft2(gray)
        f_shift = np.fft.fftshift(f_transform)
        
        # Crear perturbaciÃ³n en el dominio de frecuencia
        rows, cols = gray.shape
        crow, ccol = rows // 2, cols // 2
        
        # Generar ruido aleatorio en frecuencias especÃ­ficas
        noise_mask = np.random.normal(1.0, intensity, (rows, cols))
        
        # Aplicar mÃ¡scara para preservar frecuencias centrales (caracterÃ­sticas principales)
        preservation_radius = min(rows, cols) // 8
        y, x = np.ogrid[:rows, :cols]
        center_mask = (x - ccol) ** 2 + (y - crow) ** 2 <= preservation_radius ** 2
        noise_mask[center_mask] = 1.0
        
        # Aplicar perturbaciÃ³n
        f_shift_augmented = f_shift * noise_mask
        
        # Transformada inversa
        f_ishift = np.fft.ifftshift(f_shift_augmented)
        img_back = np.fft.ifft2(f_ishift)
        img_back = np.real(img_back)
        
        # Normalizar y convertir de vuelta
        img_back = np.clip(img_back, 0, 255).astype(np.uint8)
        
        if len(image.shape) == 3:
            # Reconstituir imagen a color
            result = image.copy()
            # Aplicar transformaciÃ³n al canal de luminancia en espacio HSV
            hsv = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2HSV)
            hsv[:, :, 2] = img_back
            result = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB).astype(np.float32) / 255.0
            return result
        else:
            return img_back.astype(np.float32) / 255.0
    
    def interference_pattern_augmentation(self, image: np.ndarray) -> np.ndarray:
        """
        Augmentation que simula variaciones en patrones de interferencia
        
        Args:
            image: Imagen de entrada
            
        Returns:
            Imagen con patrones de interferencia modificados
        """
        h, w = image.shape[:2]
        
        # Generar patrÃ³n sinusoidal aleatorio
        frequency = random.uniform(0.5, 2.0)
        phase = random.uniform(0, 2 * np.pi)
        amplitude = random.uniform(0.02, 0.08)
        
        # Crear coordenadas
        x = np.linspace(0, 2 * np.pi * frequency, w)
        y = np.linspace(0, 2 * np.pi * frequency, h)
        X, Y = np.meshgrid(x, y)
        
        # Generar patrÃ³n de interferencia
        interference = amplitude * np.sin(X + phase) * np.sin(Y + phase)
        
        # Aplicar el patrÃ³n
        if len(image.shape) == 3:
            interference = np.expand_dims(interference, axis=2)
            interference = np.repeat(interference, 3, axis=2)
        
        augmented = image + interference
        return np.clip(augmented, 0, 1)
    
    def mixup_augmentation(self, image1: np.ndarray, image2: np.ndarray, 
                          label1: int, label2: int, alpha: float = 0.2) -> Tuple[np.ndarray, float]:
        """
        ImplementaciÃ³n de Mixup para hologramas
        
        Args:
            image1, image2: ImÃ¡genes a mezclar
            label1, label2: Etiquetas correspondientes
            alpha: ParÃ¡metro de la distribuciÃ³n Beta
            
        Returns:
            Imagen mezclada y etiqueta interpolada
        """
        if alpha > 0:
            lam = np.random.beta(alpha, alpha)
        else:
            lam = 1
        
        mixed_image = lam * image1 + (1 - lam) * image2
        mixed_label = lam * label1 + (1 - lam) * label2
        
        return mixed_image, mixed_label
    
    def cutmix_augmentation(self, image1: np.ndarray, image2: np.ndarray,
                           label1: int, label2: int, alpha: float = 1.0) -> Tuple[np.ndarray, float]:
        """
        ImplementaciÃ³n de CutMix para hologramas
        
        Args:
            image1, image2: ImÃ¡genes a mezclar
            label1, label2: Etiquetas correspondientes
            alpha: ParÃ¡metro para determinar el tamaÃ±o del corte
            
        Returns:
            Imagen con CutMix y etiqueta ajustada
        """
        h, w = image1.shape[:2]
        
        # Generar parÃ¡metros del corte
        lam = np.random.beta(alpha, alpha)
        cut_rat = np.sqrt(1. - lam)
        cut_w = int(w * cut_rat)
        cut_h = int(h * cut_rat)
        
        # PosiciÃ³n aleatoria del corte
        cx = np.random.randint(w)
        cy = np.random.randint(h)
        
        bbx1 = np.clip(cx - cut_w // 2, 0, w)
        bby1 = np.clip(cy - cut_h // 2, 0, h)
        bbx2 = np.clip(cx + cut_w // 2, 0, w)
        bby2 = np.clip(cy + cut_h // 2, 0, h)
        
        # Crear imagen mezclada
        mixed_image = image1.copy()
        mixed_image[bby1:bby2, bbx1:bbx2] = image2[bby1:bby2, bbx1:bbx2]
        
        # Ajustar etiqueta segÃºn el Ã¡rea mezclada
        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (w * h))
        mixed_label = lam * label1 + (1 - lam) * label2
        
        return mixed_image, mixed_label
    
    def augment_single_image(self, image: np.ndarray, label: int = None) -> List[Tuple[np.ndarray, int]]:
        """
        Aplicar mÃºltiples augmentations a una sola imagen
        
        Args:
            image: Imagen original
            label: Etiqueta de la imagen
            
        Returns:
            Lista de imÃ¡genes augmentadas con sus etiquetas
        """
        augmented_images = []
        
        # Imagen original
        augmented_images.append((image, label))
        
        # Aplicar augmentations bÃ¡sicas mÃºltiples veces
        for i in range(self.augmentation_factor - 1):
            
            # Seleccionar tipo de augmentation
            aug_type = random.choice(['basic', 'visual', 'hologram', 'combined'])
            
            # Convertir a formato uint8 para albumentations
            img_uint8 = (image * 255).astype(np.uint8)
            
            if aug_type == 'basic':
                augmented = self.basic_augmentations(image=img_uint8)['image']
            elif aug_type == 'visual':
                augmented = self.visual_augmentations(image=img_uint8)['image']
            elif aug_type == 'hologram':
                augmented = self.hologram_augmentations(image=img_uint8)['image']
            else:
                augmented = self.combined_pipeline(image=img_uint8)['image']
            
            # Convertir de vuelta a float32
            augmented = augmented.astype(np.float32) / 255.0
            
            # Aplicar augmentations especÃ­ficas para hologramas si estÃ¡ habilitado
            if self.preserve_hologram_features:
                if random.random() < 0.3:
                    augmented = self.frequency_domain_augmentation(augmented)
                if random.random() < 0.2:
                    augmented = self.interference_pattern_augmentation(augmented)
            
            augmented_images.append((augmented, label))
        
        return augmented_images
    
    def augment_dataset(self, X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        Aplicar data augmentation a todo el dataset
        
        Args:
            X: Array de imÃ¡genes
            y: Array de etiquetas
            
        Returns:
            Dataset augmentado
        """
        print(f"ğŸ”„ Aplicando data augmentation (factor: {self.augmentation_factor})...")
        print(f"   Dataset original: {X.shape[0]} imÃ¡genes")
        
        augmented_X = []
        augmented_y = []
        
        # Procesar cada imagen
        for i, (image, label) in enumerate(zip(X, y)):
            if i % 20 == 0:
                print(f"   Progreso: {i+1}/{len(X)}")
            
            # Aplicar augmentations bÃ¡sicas
            aug_images = self.augment_single_image(image, label)
            
            for aug_img, aug_label in aug_images:
                augmented_X.append(aug_img)
                augmented_y.append(aug_label)
        
        # Aplicar tÃ©cnicas avanzadas si estÃ¡ habilitado
        if self.apply_advanced_techniques:
            print("   â””â”€ Aplicando tÃ©cnicas avanzadas (Mixup, CutMix)...")
            advanced_X, advanced_y = self._apply_advanced_augmentations(augmented_X, augmented_y)
            augmented_X.extend(advanced_X)
            augmented_y.extend(advanced_y)
        
        # Convertir a arrays numpy
        X_augmented = np.array(augmented_X)
        y_augmented = np.array(augmented_y)
        
        # Mezclar el dataset
        indices = np.random.permutation(len(X_augmented))
        X_augmented = X_augmented[indices]
        y_augmented = y_augmented[indices]
        
        print(f"âœ… Data augmentation completado!")
        print(f"   Dataset augmentado: {X_augmented.shape[0]} imÃ¡genes")
        print(f"   Factor de aumento: {X_augmented.shape[0] / X.shape[0]:.1f}x")
        
        # Guardar estadÃ­sticas
        self.augmentation_stats = {
            'original_size': int(X.shape[0]),
            'augmented_size': int(X_augmented.shape[0]),
            'augmentation_factor': self.augmentation_factor,
            'multiplication_achieved': float(X_augmented.shape[0] / X.shape[0]),
            'advanced_techniques_used': self.apply_advanced_techniques,
            'hologram_features_preserved': self.preserve_hologram_features
        }
        
        return X_augmented, y_augmented
    
    def _apply_advanced_augmentations(self, X_list: List[np.ndarray], 
                                    y_list: List[int], 
                                    n_samples: int = None) -> Tuple[List[np.ndarray], List[int]]:
        """
        Aplicar tÃ©cnicas avanzadas como Mixup y CutMix
        
        Args:
            X_list: Lista de imÃ¡genes
            y_list: Lista de etiquetas
            n_samples: NÃºmero de muestras a generar
            
        Returns:
            ImÃ¡genes y etiquetas generadas con tÃ©cnicas avanzadas
        """
        if n_samples is None:
            n_samples = len(X_list) // 4  # 25% del dataset con tÃ©cnicas avanzadas
        
        advanced_X = []
        advanced_y = []
        
        for _ in range(n_samples):
            # Seleccionar dos imÃ¡genes aleatorias
            idx1, idx2 = random.sample(range(len(X_list)), 2)
            img1, label1 = X_list[idx1], y_list[idx1]
            img2, label2 = X_list[idx2], y_list[idx2]
            
            # Aplicar Mixup o CutMix aleatoriamente
            if random.random() < 0.5:
                # Mixup
                mixed_img, mixed_label = self.mixup_augmentation(img1, img2, label1, label2)
            else:
                # CutMix
                mixed_img, mixed_label = self.cutmix_augmentation(img1, img2, label1, label2)
            
            advanced_X.append(mixed_img)
            advanced_y.append(mixed_label)
        
        return advanced_X, advanced_y
    
    def visualize_augmentations(self, image: np.ndarray, label: int = None, 
                               save_path: str = "augmentation_examples.png"):
        """
        Visualizar diferentes tipos de augmentation aplicados a una imagen
        
        Args:
            image: Imagen original
            label: Etiqueta de la imagen
            save_path: Ruta donde guardar la visualizaciÃ³n
        """
        print("ğŸ–¼ï¸ Generando visualizaciÃ³n de data augmentations...")
        
        # Generar ejemplos de diferentes augmentations
        img_uint8 = (image * 255).astype(np.uint8)
        
        # Aplicar diferentes pipelines
        basic_aug = self.basic_augmentations(image=img_uint8)['image']
        visual_aug = self.visual_augmentations(image=img_uint8)['image']
        hologram_aug = self.hologram_augmentations(image=img_uint8)['image']
        combined_aug = self.combined_pipeline(image=img_uint8)['image']
        
        # Aplicar augmentations especÃ­ficas
        freq_aug = (self.frequency_domain_augmentation(image) * 255).astype(np.uint8)
        interference_aug = (self.interference_pattern_augmentation(image) * 255).astype(np.uint8)
        
        # Crear visualizaciÃ³n
        fig, axes = plt.subplots(2, 4, figsize=(20, 10))
        fig.suptitle('Ejemplos de Data Augmentation para Hologramas', fontsize=16, fontweight='bold')
        
        images = [
            (img_uint8, "Original"),
            (basic_aug, "Transformaciones\nGeomÃ©tricas"),
            (visual_aug, "Mejoras\nVisuales"),
            (hologram_aug, "Augmentations\nHologrÃ¡ficas"),
            (combined_aug, "Pipeline\nCombinado"),
            (freq_aug, "Dominio de\nFrecuencia"),
            (interference_aug, "Patrones de\nInterferencia"),
            (img_uint8, "Reservado para\nTÃ©cnicas Avanzadas")
        ]
        
        for idx, (img, title) in enumerate(images):
            row = idx // 4
            col = idx % 4
            axes[row, col].imshow(img)
            axes[row, col].set_title(title, fontsize=12)
            axes[row, col].axis('off')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… VisualizaciÃ³n guardada en: {save_path}")
    
    def save_augmentation_config(self, filepath: str = "augmentation_config.json"):
        """
        Guardar configuraciÃ³n de augmentation
        
        Args:
            filepath: Ruta donde guardar la configuraciÃ³n
        """
        import json
        
        config = {
            'augmentation_factor': self.augmentation_factor,
            'preserve_hologram_features': self.preserve_hologram_features,
            'apply_advanced_techniques': self.apply_advanced_techniques,
            'augmentation_stats': self.augmentation_stats
        }
        
        with open(filepath, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"ğŸ’¾ ConfiguraciÃ³n de augmentation guardada en: {filepath}")

def main():
    """
    FunciÃ³n principal para demostrar el data augmentation
    """
    print("ğŸ”¬ DATA AUGMENTATION PARA HOLOGRAMAS")
    print("=" * 50)
    
    # Cargar dataset preprocesado
    print("ğŸ“ Cargando dataset preprocesado...")
    data = np.load('preprocessed_dataset.npz')
    X_train, y_train = data['X_train'], data['y_train']
    X_test, y_test = data['X_test'], data['y_test']
    
    print(f"   Dataset original: {X_train.shape[0]} imÃ¡genes de entrenamiento")
    
    # Inicializar augmentador
    augmentator = HologramAugmentator(
        augmentation_factor=8,
        preserve_hologram_features=True,
        apply_advanced_techniques=True
    )
    
    # Generar visualizaciÃ³n de augmentations
    sample_image = X_train[0]
    sample_label = y_train[0]
    augmentator.visualize_augmentations(sample_image, sample_label)
    
    # Aplicar data augmentation al dataset de entrenamiento
    X_train_augmented, y_train_augmented = augmentator.augment_dataset(X_train, y_train)
    
    # Mostrar estadÃ­sticas
    print(f"\nğŸ“Š ESTADÃSTICAS DE DATA AUGMENTATION:")
    print("=" * 50)
    stats = augmentator.augmentation_stats
    print(f"Dataset original: {stats['original_size']} imÃ¡genes")
    print(f"Dataset augmentado: {stats['augmented_size']} imÃ¡genes")
    print(f"Factor configurado: {stats['augmentation_factor']}x")
    print(f"Factor real alcanzado: {stats['multiplication_achieved']:.1f}x")
    print(f"TÃ©cnicas avanzadas: {'âœ…' if stats['advanced_techniques_used'] else 'âŒ'}")
    print(f"PreservaciÃ³n hologrÃ¡fica: {'âœ…' if stats['hologram_features_preserved'] else 'âŒ'}")
    
    # Guardar dataset augmentado
    print(f"\nğŸ’¾ Guardando dataset augmentado...")
    np.savez_compressed(
        'augmented_dataset.npz',
        X_train=X_train_augmented,
        y_train=y_train_augmented,
        X_test=X_test,
        y_test=y_test
    )
    
    # Guardar configuraciÃ³n
    augmentator.save_augmentation_config()
    
    print("âœ… Data augmentation completado!")
    print("ğŸ“ Archivos generados:")
    print("   â€¢ augmentation_examples.png")
    print("   â€¢ augmented_dataset.npz")
    print("   â€¢ augmentation_config.json")

if __name__ == "__main__":
    main()
```

Primero voy a instalar las librerÃ­as faltantes y corregir los errores de tipo:

Ahora voy a corregir los errores de tipo donde se pasa None en lugar de int:

```python
    def augment_single_image(self, image: np.ndarray, label: int = None) -> List[Tuple[np.ndarray, int]]:
        """
        Aplicar mÃºltiples augmentations a una sola imagen
        
        Args:
            image: Imagen original
            label: Etiqueta de la imagen
            
        Returns:
            Lista de imÃ¡genes augmentadas con sus etiquetas
        """
        augmented_images = []
        
        # Imagen original
        augmented_images.append((image, label))

->

    def augment_single_image(self, image: np.ndarray, label: int = 0) -> List[Tuple[np.ndarray, int]]:
        """
        Aplicar mÃºltiples augmentations a una sola imagen
        
        Args:
            image: Imagen original
            label: Etiqueta de la imagen
            
        Returns:
            Lista de imÃ¡genes augmentadas con sus etiquetas
        """
        augmented_images = []
        
        # Imagen original
        augmented_images.append((image, label))
```

```python
    def visualize_augmentations(self, image: np.ndarray, label: int = None, 
                               save_path: str = "augmentation_examples.png"):

->

    def visualize_augmentations(self, image: np.ndarray, label: int = 0, 
                               save_path: str = "augmentation_examples.png"):
```

```python
augmentator.visualize_augmentations(sample_image, sample_label)
```

```python
     # Generar visualizaciÃ³n de augmentations
     sample_image = X_train[0]
     sample_label = y_train[0]
     augmentator.visualize_augmentations(sample_image, sample_label)

->

     # Generar visualizaciÃ³n de augmentations
     sample_image = X_train[0]
     sample_label = int(y_train[0])
     augmentator.visualize_augmentations(sample_image, sample_label)
```

Los errores de importaciÃ³n no son problemÃ¡ticos ya que las librerÃ­as estÃ¡n instaladas. Voy a ejecutar el script de data augmentation:

Voy a corregir el error de indentaciÃ³n:

```python
     # Generar visualizaciÃ³n de augmentations
     sample_image = X_train[0]
      sample_label = int(y_train[0])
     augmentator.visualize_augmentations(sample_image, sample_label)

->

     # Generar visualizaciÃ³n de augmentations
     sample_image = X_train[0]
     sample_label = int(y_train[0])
     augmentator.visualize_augmentations(sample_image, sample_label)
```

```python
    )
    
    # Generar visualizaciÃ³n de augmentations
    sample_image = X_train[0]
    sample_label = int(y_train[0])
    augmentator.visualize_augmentations(sample_image, sample_label)
    
    # Aplicar data augmentation al dataset de entrenamiento
```

El problema es que estamos importando PyTorch que no necesitamos. Voy a quitar esa importaciÃ³n:

```python
import numpy as np
import cv2
import random
from typing import Tuple, List, Dict, Callable, Union
import matplotlib.pyplot as plt
from scipy import ndimage
from skimage import transform, filters, exposure
import albumentations as A
import warnings
warnings.filterwarnings('ignore')
```

Perfecto, ahora intentemos ejecutar el script:

Hay un problema con la API de Albumentations. Voy a corregir los nombres de las transformaciones:

```python
        # Pipeline bÃ¡sico - transformaciones geomÃ©tricas
        self.basic_augmentations = A.Compose([
            A.RandomRotate90(p=0.5),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.3),
            A.ShiftScaleRotate(
                shift_limit=0.1, 
                scale_limit=0.1, 
                rotate_limit=15, 
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.8
            ),
            A.ElasticTransform(
                alpha=50, 
                sigma=5, 
                alpha_affine=5,
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.3
            )
        ])
        
        # Pipeline de mejoras visuales - preserva patrones hologrÃ¡ficos
        self.visual_augmentations = A.Compose([
            A.RandomBrightnessContrast(
                brightness_limit=0.15, 
                contrast_limit=0.15, 
                p=0.7
            ),
            A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),
            A.RandomGamma(gamma_limit=(80, 120), p=0.4),
            A.GaussNoise(var_limit=(10, 30), p=0.3),
            A.Blur(blur_limit=3, p=0.2)
        ])
        
        # Pipeline avanzado - tÃ©cnicas especÃ­ficas para hologramas
        self.hologram_augmentations = A.Compose([
            A.OpticalDistortion(
                distort_limit=0.1, 
                shift_limit=0.05,
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.3
            ),
            A.GridDistortion(
                num_steps=5, 
                distort_limit=0.1,
                border_mode=cv2.BORDER_REFLECT_101,
                p=0.3
            ),
            A.GaussianBlur(blur_limit=(1, 3), p=0.2),
            A.MotionBlur(blur_limit=3, p=0.2)
        ])
```

Ahora intentemos ejecutar el script nuevamente:

